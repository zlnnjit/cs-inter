> 本文取材源自公司同事的分享。



<!--more-->

## 消息中间件（MQ）概述

消息队列已经逐渐成为企业IT系统内部通信的核心手段。它具有低耦合、可靠投递、广播、流量控制等功能。当今市面上有很多主流的消息中间件，如老牌的ActiveMQ、RabbitMQ，炙手可热的Kafka，阿里巴巴自主开发RocketMQ等。

#### 1.为什么要使用MQ？

主要场景：**异步**，**解耦**，**削峰填谷**

**异步** 

主系统接收一个请求，在本地执行完SQL以后，需要分别调用A，B，C三个子系统的接口，执行时间分别为200ms，100ms，300ms，则总的执行时间为10+200+100+300 = 610(ms)。

![](http://img.bcoder.top/2020.01.26.1/1.png)

但是一旦使用了MQ之后，主系统只需要发送3条消息到MQ中的3个消息队列，然后就返回给用户了。

![](http://img.bcoder.top/2020.01.26.1/2.png)

消息发送到MQ耗时20ms，那么用户感知到这个接口的总时间就为10+20=30(ms)。



**解耦**

开始的时候，主系统在用户发生某个操作的时候，需要把用户提交的数据同时推送到A、B两个系统的时候。
随着业务快速迭代，这个时候系统C,D也想要这个数据，主系统修改接口，增加C，D的接入
随着业务再迭代，这个时候系统B不要这个数据，主系统修改接口，删除B的接入
... ...业务不断迭代， 主系统需要不断调整接口。

![](http://img.bcoder.top/2020.01.26.1/3.png)

引入MQ以后，主系统只负责将生产的数据投递到MQ，其它事情不用关心。各个子系统可以随时订阅/取消对消息的消费。

![](http://img.bcoder.top/2020.01.26.1/4.png)

解耦的同时，还增加了系统的**可恢复性**。即使一个处理消息的进程挂掉，加入队列中的消息仍然可以在系统恢复后被处理。



**削峰填谷**

DB支持的最大QPS为1000，平常的时候，用户访问请求为100QPS，系统访问正常。 高峰的时候，大量用户请求瞬间涌入，DB的请求达到5000QPS，直接被打死，绝望。

![](http://img.bcoder.top/2020.01.26.1/5.png)

引入MQ以后，消息被MQ保存起来了，然后系统就可以按照自己的消费能力来消费，比如每秒1000个数据，这样慢慢写入数据库，这样就不会打死数据库了：

![](http://img.bcoder.top/2020.01.26.1/6.png)

如果没有用MQ的情况下，并发量高峰期的时候是有一个“顶峰”的，然后高峰期过后又是一个低并发的“谷”。
但是使用了MQ之后，限制消费消息的速度为1000，但是这样一来，高峰期产生的数据势必会被积压在MQ中，高峰就被“削”掉了。

![](http://img.bcoder.top/2020.01.26.1/7.png)

#### 2. 使用了MQ以后可能会带来哪些问题？

**系统的可用性降低**

在解耦的场景中，主系统原先都是直接调用子系统A，B，C的。引入MQ以后，子系统开始订阅MQ，这时候MQ挂了怎么办？

因为多了一个风险因素。MQ可能会挂掉。数据没了，系统运行就不对了。



**系统复杂度提高**

本来我的系统通过接口调用一下就能完事的，但是加入一个MQ之后，需要考虑消息重复消费、消息丢失、甚至消息顺序性的问题。



**数据一致性**

本来好好的，主系统调用ABC系统接口，如果ABC系统出错了，会抛出异常，返回给主系统让它系统知道，这样的话就可以做回滚操作了。

但是使用了MQ之后，主系统发送完消息就完事了，认为成功了。而刚好B系统写数据库的时候失败了，但是主系统认为B已经成功了？这样一来数据就不一致了。



## RabbitMQ

#### 1.介绍

RabbitMQ是一个开源的AMQP实现，服务器端用Erlang语言编写，支持多种客户端。用于在分布式系统中存储转发消息，在易用性、扩展性、高可用性等方面表现不俗。

AMQP(Advanced Message Queuing Protocol)高级消息队列协议是应用层协议的一个开放标准，为面向消息的中间件设计。消息中间件主要用于组件之间的解耦，消息的发送者无需知道消息使用者的存在，反之亦然。AMQP的主要特征是面向消息、队列、路由（包括点对点和发布/订阅）、可靠性、安全。

![](http://img.bcoder.top/2020.01.26.1/8.png)

#### 2.重要概念

**比较重要的概念有 4 个，分别为：虚拟主机，交换机，队列，和绑定**

- **虚拟主机**：一个虚拟主机持有一组交换机、队列和绑定。为什么需要多个虚拟主机呢？很简单，RabbitMQ当中，*用户只能在虚拟主机的粒度进行权限控制。* 因此，如果需要禁止A组访问B组的交换机/队列/绑定，必须为A和B分别创建一个虚拟主机。每一个RabbitMQ服务器都有一个默认的虚拟主机“/”。

- **交换机**：Exchange 用于转发消息，但是它不会做存储* ，如果没有 Queue bind 到 Exchange 的话，它会直接丢弃掉 Producer 发送过来的消息。

- **路由键** ：消息到交换机的时候，交互机会转发到对应的队列中，那么究竟转发到哪个队列，就要根据该路由键。

- **绑定**：也就是交换机需要和队列相绑定，这其中如上图所示，是多对多的关系。

  

#### 3.交换机（Exchange）

  交换器分4种：direct，headers，topic，fanout

- **direct**：默认交换器。行为是"先匹配, 再投送"。直连接类型必须是生产者发布消息指定的**routingKey**和消费者在队列绑定时指定的**routingKey**完全相等时才能匹配到队列上。即在绑定时设定一个 **routing_key**, 消息的**routing_key** 匹配时, 才会被交换器投送到绑定的队列中去。

![](http://img.bcoder.top/2020.01.26.1/9.png)

X - Q1 就有一个 binding key，名字为 orange；X - Q2 就有 2 个 binding key，名字为 black 和 green。当消息中的 路由键 和 这个 binding key 对应上的时候，那么就知道了该消息去到哪一个队列中。



- **topic**：按规则转发消息（最灵活）。 在这种交换机下，**topic**可以进行模糊。匹配可以使用星号`*`和井号`#`这两个通配符来进行模糊匹配，其中`*`可以代替一个单词。 `#`可以替代零个或更多的单词。主题类型的转发器的消息不能随意的设置选择键（routing_key），必须是由点隔开的一系列的标识符组成。只要能模糊匹配上就能将消息映射到队列中。当一个队列的绑定键为#的时候，这个队列将会无视消息的路由键，接收所有的消息。

![](http://img.bcoder.top/2020.01.26.1/10.png)

+ **headers**：不需要路由键**routingKey**，交换机时通过Headers头部来将消息映射到队列的。Hash结构中要求携带一个键“x-match”，这个键的Value可以是any或者all，这代表消息携带的Hash是需要全部匹配(all)，还是仅匹配一个键(any)就可以了。相比直连交换机，首部交换机的优势是匹配的规则不被限定为字符串(string)而是Object类型。

![](http://img.bcoder.top/2020.01.26.1/11.png)

+ **fanout**：不需要路由键**routingKey**，转发消息到所有绑定队列。

![](http://img.bcoder.top/2020.01.26.1/12.png)

#### 4. 消息不丢失与消息确认ACK

消息丢失会发生在：

- 生产者将数据发送到rabbitmq的时候,可能数据在网络传输中搞丢了，这个时候RabbitMQ收不到消息，消息就丢了。

- RabbitMQ集群也会弄丢消息，这个问题在官方文档的教程中也提到过，就是说在消息发送到RabbitMQ之后，默认是没有落地磁盘的，万一RabbitMQ宕机了，这个时候消息就丢失了。

- RabbitMQ消费端弄丢了数据的情况是这样的：在消费消息的时候，刚拿到消息，结果进程挂了，这个时候RabbitMQ就会认为你已经消费成功了，这条数据就丢了。

  

**生产者消息确认**

当生产者发布消息到RabbitMQ中，生产者需要知道是否真的已经发送到RabbitMQ中，需要RabbitMQ告诉生产者。主要通过以下两种方式：

- **事务机制**： 在生产者发送消息之前，通过`channel.txSelect`开启一个事务，接着发送消息。
  如果消息没有成功被RabbitMQ接收到，生产者会收到异常，此时就可以进行事务回滚`channel.txRollback`然后重新发送。假如RabbitMQ收到了这个消息，就可以提交事务`channel.txCommit`。

  该方式生产者的吞吐量和性能都会降低很多。
  例：

  ```java
       channel.txSelect();
        try {
            channel.basicPublish(ex_name, rt_name, null, "hello".getBytes());
            //显示抛出RuntimeException
            int a = 1 / 0;
            channel.txCommit();
        } catch (IOException e) {
            e.printStackTrace();
            channel.txRollback();
        }
  ```

  > `channel.txSelect()`: 将当前信道设置成事务模式
  > `channel.txCommit()`: 用于提交事务
  > `channel.txRollback()`: 用于回滚事务



- **Confirm机制**：有在该信道上面发布的消息都会被指派一个唯一的id(从1开始)，一旦消息被投递到匹配的队列之后，rabbitmq就会发送一个确认(`Basic.Ack`)和`deliverTag`(消息id)给生产者。如果消息和队列是持久化的那么消息会在持久化之后被发出。rabbitmq除了回传`deliverTag`之外，还有`multiple`参数，表示到这个序号之前所有的消息都得到了处理。**所有的消息只会被Ack或Nack一次，不会出现既被Ack又被Nack**

  ```java
  //将信道设置成确认模式
  channel.confirmSelect();
  channel.basicPublish(ex_name, rt_name, null, "hello".getBytes());
  //同步确认
  if (!channel.waitForConfirms()) {
  	System.out.println("发送失败...");
  } else {
  	System.out.println("发送成功...");
  }
  ```

  ```java
  channel.confirmSelect();
  //添加监听器
  channel.addConfirmListener(new ConfirmListener() {
  	@Override
      public void handleAck(long deliveryTag, boolean multiple) throws IOException {
      	System.out.println("Ack: tag no: " + deliveryTag + " multiple: " + multiple);
      }
  	@Override
  	public void handleNack(long deliveryTag, boolean multiple) throws IOException {
  		System.out.println("Nack: tag no: " + deliveryTag + " multiple: " + multiple);
  	}
  });
  channel.basicPublish(ex_name, rt_name, null, "hello".getBytes());
  ```

  > `channel.confirmSelect()`: 将信道设置成确认模式
  > `channel.waitForConfirms()`: 同步确认
  > `channel.addConfirmListener()`: 异步确认



事务机制和confirm机制**最大的不同**在于事务机制是同步的，提交一个事务之后会阻塞在那儿。但是confirm机制是异步的，发送一个消息之后就可以发送下一个消息，然后那个消息rabbitmq接收了之后会异步回调你一个接口通知你这个消息接收到了。一般在生产者这块避免数据丢失，都是用confirm机制的。



**Rabbitmq持久化数据**

RabbitMQ提供了一个**持久化**的机制，消息写入之后会持久化到磁盘。这样哪怕是宕机了，恢复之后也会自动恢复之前存储的数据，这样的机制可以确保消息不会丢失。设置持久化步骤：

- step1.创建queue的时候将其设置为持久化的，保证rabbitmq持久化queue的元数据，但是不会持久化queue里的数据。
- step2.发送消息的时候将消息的deliveryMode设置为2，就是将消息设置为持久化的，此时rabbitmq就会将消息持久化到磁盘上去。

配合confirm机制使用时，就是在消息持久化到磁盘之后才会给生产者发送ack消息。



**消费者消息确认**

在消费者收到消息的时候，会发送一个ack给RabbitMQ，告诉RabbitMQ这条消息被消费到了，这样RabbitMQ就会把消息删除。默认情况下这个发送ack的操作是自动提交的，也就是说消费者一收到这个消息就会自动返回ack给RabbitMQ，所以会出现丢消息的问题。所以要手动关闭RabbitMQ消费者的自动提交ack,在消费者处理完这条消息之后再手动提交ack。

```java
boolean autoAck = false;
channel.basicConsume(QUEUE_NAME, autoAck, consumer);
```

当消费者收到消息在合适的时候来显示的进行确认，说我已经接收到了该消息了，RabbitMQ可以从队列中删除该消息了，可以通过显示调用`channel.basicAck(envelope.getDeliveryTag(), false)`;来告诉消息服务器来删除消息。

```java
Consumer consumer = new DefaultConsumer(channel) {
   @Override
   public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException {
       String message = new String(body, "UTF-8");
       System.out.println(message);
       channel.basicAck(envelope.getDeliveryTag(), false);
   }
};
channel.basicConsume(QUEUE_NAME, false, consumer);
```



#### 5.高可用

RabbitMQ集群模式主要有：单机模式，普通集群模式，镜像集群模式。



**单机模式**

单机模式就是demo级别的，就是说只有一台机器部署了一个RabbitMQ程序。这个会存在单点问题，宕机就玩完了，没什么高可用性可言。



**普通集群模式**

这个模式的意思就是在多台机器上启动多个rabbitmq实例。此种模式消息只存在其中一个节点上，集群中的其他节点仅有相同的元数据(即队列元数据)，当拥有消息的节点宕机了，那么其他节点就无法获取故障节点中尚未消费的消息，如果故障节点使用了持久化，那只能等故障节点恢复后才能从该节点上的队列进行消费，如果没有持久化，那么所有消息将丢失。

该方案主要是提高吞吐量的，就是说让集群中多个节点来服务某个queue的读写操作。



**镜像集群模式**

创建的queue无论元数据还是queue里的消息都会存在于多个实例上，每次写消息到queue的时候，都会自动把消息到多个实例的queue里进行消息同步。这样的话任何一个机器宕机了别的实例都可以用提供服务，这样就做到了真正的高可用了。

![](http://img.bcoder.top/2020.01.26.1/13.png)

缺点：

- 1.性能开销过高，消息需要同步所有机器，会导致网络带宽压力和消耗很重.

- 2.扩展性低：无法解决某个queue数据量特别大的情况，导致queue无法线性拓展。就算加了机器，那个机器也会包含queue的所有数据，queue的数据没有做到分布式存储。

  

**主从集群**

是指一对主备独立服务器，并设置一台负载均衡器来处理故障转移，使用HAproxy设置备用服务器很简单,使用backup来标记一下，只有当主服务器不可用时才使用备用服务器。

![](http://img.bcoder.top/2020.01.26.1/14.png)

## RocketMQ

#### 1.介绍

RocketMQ是一个纯Java、分布式、队列模型的开源消息中间件，前身是MetaQ，是阿里参考Kafka特点研发的一个队列模型的消息中间件，后开源给apache基金会成为了apache的顶级开源项目，具有高性能、高可靠、高实时、分布式特点。在阿里集团也被广泛应用在订单，交易，充值，流计算，消息推送，日志流式处理，**binglog**分发等场景。



#### 2.架构组成与重要概念

**RocketMQ**的组件都是**集群**部署的，这是他**吞吐量大**，**高可用**的原因之一。主要分为主要四大核心：**NameServer**、**Broker**、**Producer**以及**Consumer**。

![](http://img.bcoder.top/2020.01.26.1/15.png)

**NameServer**：是消息队列的协调者，Broker向它注册路由信息，同时Client向其获取路由信息，类似zookeeper。NameServer本身是没有状态的，并且多个NameServer直接并没有通信，可以横向扩展多台，Broker会和每一台NameServer建立长连接；



**Broker**: Broker是RocketMQ的核心，提供了消息的接收，存储，拉取等功能，一般都需要保证Broker的高可用，所以会配置Broker Slave，当Master挂掉之后，Consumer然后可以消费Slave；

Broker分为Master和Slave，一个Master可以对应多个Slave，Master与Slave的对应关系通过指定相同的BrokerName，不同的BrokerId来定义，BrokerId为0表示Master，非0表示Slave；

底层的通信和连接都是**基于Netty实现**的。



**Producer**：消息队列的生产者，需要与NameServer建立连接，从NameServer获取Topic路由信息，并向提供Topic服务的Broker Master建立连接；消息由**Producer**通过多种负载均衡模式发送到**Broker**集群。它提供了3中发送方式：同步、异步和单向。

![](http://img.bcoder.top/2020.01.26.1/16.jpg)

**Consumer**: 消息队列的消费者，同样与NameServer建立连接，从NameServer获取Topic路由信息，并向提供Topic服务的Broker Master，Slave建立连接；支持PUSH和PULL两种消费模式，支持**集群消费**和**广播消息**，提供**实时的消息订阅机制**。

- 集群消费: 该模式下一个消费者集群共同消费一个主题的多个队列，一个队列只会被一个消费者消费，如果某个消费者挂掉，分组内其它消费者会接替挂掉的消费者继续消费。

![](http://img.bcoder.top/2020.01.26.1/17.png)

+ 广播消费: 广播消费消息会发给消费者组中的每一个消费者进行消费

3. #### 消息领域模型

![](http://img.bcoder.top/2020.01.26.1/18.png)

**Message**:  就是要传输的消息；一条消息必须有一个主题（Topic），一条消息也可以拥有一个可选的标签（Tag）和额处的键值对。



**Topic**:  可以看做消息的规类，它是消息的第一级类型。比如一个电商系统可以分为：交易消息、物流消息等，一条消息必须有一个 Topic 。

一个 Topic 可以有0个、1个、多个生产者向其发送消息，一个生产者也可以同时向不同的 Topic 发送消息。一个 Topic 也可以被 0个、1个、多个消费者订阅。



**Tag**:  可以看作子主题，它是消息的第二级类型，用于为用户提供额外的灵活性。使用标签，同一业务模块不同目的的消息就可以用相同 Topic 而不同的 **Tag** 来标识。比如交易消息又可以分为：交易创建消息、交易完成消息等，一条消息可以没有 **Tag** 。



**Group**: 分组，一个组可以订阅多个Topic。分为ProducerGroup，ConsumerGroup，代表某一类的生产者和消费者，一般来说同一个服务可以作为Group，同一个Group一般来说发送和消费的消息都是一样的。



**Queue**: 每个Queue内部是有序的，在rocketmq中分为读和写两种队列，一般数量一致。



**Message Queue**: 主题被划分为一个或多个子主题，即消息队列。主题被划分为一个或多个子主题，即消息队列。



**Offset**: 所有消息队列都是持久化，长度无限的数据结构。访问其中的存储单元使用Offset 来访问。



#### 4. 消息确认与刷盘

不同的消息队列发送的确认信息形式不同。例如**RabbitMQ**是发送一个ACK确认消息，**RocketMQ**是返回一个CONSUME_SUCCESS成功标志。

消息收到以后，需要对消息进行存储和复制。**RocketMQ**对消息的刷盘提供了同步和异步的策略。选择同步刷盘可以尽最大程度满足我们的消息不会丢失。

- 同步刷盘：使用**NIO**中的 MappedByteBuffer.force() 将映射区的数据写入到磁盘，如果刷盘超时会给返回FLUSH_DISK_TIMEOUT。
- 异步刷盘：在**Broker**把消息写到**CommitLog**映射区后，就会等待写入完成。超时不会返回刷盘相关信息。

![](http://img.bcoder.top/2020.01.26.1/19.jpg)

主从同步也提供了同步和异步，选择同步可以提升可用性，但是消息的发送RT时间会下降。



#### 5.顺序消息

生产者消费者一般需要保证顺序消息的话，可能就是一个业务场景下的，比如订单的创建、支付、发货、收货。

**RocketMQ**提供了**MessageQueueSelector**队列。我们可使用**Hash取模法**，让同一个订单发送到同一个队列中，再使用同步发送，只有同个订单的创建消息发送成功，再发送支付消息。这样，我们保证了发送有序。

![](http://img.bcoder.top/2020.01.26.1/20.png)

例：生产者

```java
public class OrderedProducer {
    public static void main(String[] args) throws Exception {
        //Instantiate with a producer group name.
        DefaultMQProducer producer = new DefaultMQProducer("example_group_name");
        producer.setNamesrvAddr("172.171.15.98:9876");
        //Launch the instance.
        producer.start();
        String[] tags = new String[]{"TagA", "TagB", "TagC", "TagD", "TagE"};
        for (int i = 0; i < 100; i++) {
            int orderId = i % 10;
            //Create a message instance, specifying topic, tag and message body.
            Message msg = new Message("TopicTestjjj", tags[i % tags.length], "KEY" + i,
                    ("Hello RocketMQ " + i).getBytes(RemotingHelper.DEFAULT_CHARSET));
            SendResult sendResult = producer.send(msg, new MessageQueueSelector() {
                @Override
                public MessageQueue select(List<MessageQueue> mqs, Message msg, Object arg) {
                    Integer id = (Integer) arg;
                    int index = id % mqs.size();
                    return mqs.get(index);
                }
            }, orderId);
            System.out.printf("%s%n", sendResult);
        }
        //server shutdown
        producer.shutdown();
    }
}
```



**RocketMQ**的topic内的队列机制,可以保证存储满足**FIFO**。

一个订单你发送的时候放到一个队列里面去，同一个的订单号Hash是一样的结果，那肯定是同一个消费者消费，那顺序就可以保证了。

例: 消费者

```java
public class OrderedConsumer {
    public static void main(String[] args) throws Exception {
        DefaultMQPushConsumer consumer = new DefaultMQPushConsumer("example_group_name");
        consumer.setNamesrvAddr("172.171.15.98:9876");
        consumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_FIRST_OFFSET);
        consumer.subscribe("TopicTest", "TagA || TagC || TagD");
        consumer.registerMessageListener(new MessageListenerOrderly() {
            AtomicLong consumeTimes = new AtomicLong(0);
            @Override
            public ConsumeOrderlyStatus consumeMessage(List<MessageExt> msgs, ConsumeOrderlyContext context) {
                context.setAutoCommit(false);
                System.out.printf(Thread.currentThread().getName() + " Receive New Messages: " + msgs + "%n");
                this.consumeTimes.incrementAndGet();
                if ((this.consumeTimes.get() % 2) == 0) {
                    return ConsumeOrderlyStatus.SUCCESS;
                } else if ((this.consumeTimes.get() % 3) == 0) {
                    return ConsumeOrderlyStatus.ROLLBACK;
                } else if ((this.consumeTimes.get() % 4) == 0) {
                    return ConsumeOrderlyStatus.COMMIT;
                } else if ((this.consumeTimes.get() % 5) == 0) {
                    context.setSuspendCurrentQueueTimeMillis(3000);
                    return ConsumeOrderlyStatus.SUSPEND_CURRENT_QUEUE_A_MOMENT;
                }
                return ConsumeOrderlyStatus.SUCCESS;
            }
        });
        consumer.start();
        System.out.printf("Consumer Started.%n");
    }
}
```

#### 6.分布式事务



**Half Message(半消息)**

是指暂时不能被consumer消费的消息。producer 已经把消息成功发送到了 Broker ，但此消息被标记为**暂不能投递**状态，处于该种状态下的消息称为半消息。需要producer对消息**二次确认**后，consumer才能去消费它。



**消息回查**

由于网络闪段，生产者应用重启等原因。导致 **Producer** 端一直没有对 **Half Message(半消息)** 进行 **二次确认**。这时**Brock**服务器会定时扫描**长期处于半消息**的消息，会主动询问 **Producer**端 该消息的最终状态(**Commit或者Rollback**)，即为 **消息回查**。

![](http://img.bcoder.top/2020.01.26.1/21.jpg)

> 1:  A服务先发送个Half Message给Brock端，消息中携带 B服务 即将要+100元的信息。
>
> 2:  当A服务知道Half Message发送成功后，那么开始第3步执行本地事务。
>
> 3：执行本地事务(会有三种情况1、执行成功。2、执行失败。3、网络等原因导致没有响应)。
>
> 4：如果本地事务成功，那么Product像Brock服务器发送Commit,这样B服务就可以消费该message。
>
> 5：果本地事务失败，那么Product像Brock服务器发送Rollback,那么就会直接删除上面这条半消息。
>
> 6：如果因为网络等原因迟迟没有返回失败还是成功，那么会执行RocketMQ的回调接口,来进行事务的回查。
>
> 7：根据回查的结果，对该消息commit/rollback。

#### 7.其它



**定时消息**

定时消息是指消息发到**Broker**后，不能立刻被**Consumer**消费，要到特定的时间点或者等待特定的时间后才能被消费。

**RocketMQ**支持定时消息，但是不支持任意时间精度，支持特定的level，例如定时5s，10s，1m等。



**消息过滤**

- **Broker**端消息过滤：在**Broker**中，按照**Consumer**的要求做过滤，优点是减少了对于**Consumer**无用消息的网络传输。缺点是增加了Broker的负担，实现相对复杂。

- **Consumer**端消息过滤：这种过滤方式可由应用完全自定义实现，但是缺点是很多无用的消息要传输到**Consumer**端。

  

**消息堆积**

消息中间件的主要功能是异步解耦，还有个重要功能是挡住前端的数据洪峰，保证后端系统的稳定性，这就要求消息中间件具有一定的消息堆积能力，消息堆积分以下两种情况：

- 消息堆积在内存**Buffer**：一旦超过内存**Buffer**，可以根据一定的丢弃策略来丢弃消息，如CORBA Notification规范中描述。适合能容忍丢弃消息的业务，这种情况消息的堆积能力主要在于内存**Buffer**大小，而且消息堆积后，性能下降不会太大，因为内存中数据多少对于对外提供的访问能力影响有限。

- 消息堆积到持久化存储系统中：例如DB，KV存储，文件记录形式。当消息不能在内存Cache命中时，要不可避免的访问磁盘，会产生大量读IO，读IO的吞吐量直接决定了消息堆积后的访问能力。

  

**批量消息**

成批发送消息能够提高传递小消息的性能。批量消息要求：

- 相同的topic，相同的 waitStoreMsgOK，不支持定时任务
- 单批次的消息总大小不能超过1MiB

## Kafka

#### 1.介绍

Kafka 起初是 由 LinkedIn 公司采用 Scala 语言开发的一个多分区、多副本且基于 ZooKeeper 协调的分布式消息系统。它以高吞吐、可持久化、可水平扩展、支持流数据处理等多种特性而被广泛使用。

Kafka 受到越来越多的青睐，与它所“扮演”的三大角色是分不开的：

- **消息系统**：Kafka 和传统的消息系统（也称作消息中间件）都具备系统解耦、冗余存储、流量削峰、缓冲、异步通信、扩展性、可恢复性等功能。与此同时，它还提供消息顺序性保障及回溯消费的功能。

- **存储系统**：Kafka 把消息持久化到磁盘，相比于其他基于内存存储的系统而言，有效地降低了数据丢失的风险。也正是得益于 Kafka 的消息持久化功能和多副本机制，我们可以把 Kafka 作为长期的数据存储系统来使用，只需要把对应的数据保留策略设置为“永久”或启用主题的日志压缩功能即可。

- **流式处理平台**：Kafka 不仅为每个流行的流式处理框架提供了可靠的数据来源，还提供了一个完整的流式处理类库，比如窗口、连接、变换和聚合等各类操作。

  

#### 2.架构组成与重要概念

一个典型的 Kafka 体系架构包括若干 Producer、若干 Broker、若干 Consumer，以及一个 ZooKeeper 集群。

![](http://img.bcoder.top/2020.01.26.1/22.png)



**ZooKeeper**: 是 Kafka 用来负责集群元数据的管理、控制器的选举等操作的。

**Producer**:  生产者，也就是发送消息的一方。生产者负责创建消息，然后将其投递到 Kafka 中。

**Broker**: 负责将收到的消息存储到磁盘中。 对于 Kafka 而言，Broker 可以简单地看作一个独立的 Kafka 服务节点或 Kafka 服务实例。大多数情况下也可以将 Broker 看作一台 Kafka 服务器，前提是这台服务器上只部署了一个 Kafka 实例。一个或多个 Broker 组成了一个 Kafka 集群。

**Consumer**: 消费者，也就是接收消息的一方。消费者连接到 Kafka 上并接收消息，进而进行相应的业务逻辑处理。

**Topic** 和 **Partition**: 消息以主题(Topic)为单位进行归类，生产者负责将消息发送到特定的主题(发送到 Kafka 集群中的每一条消息都要指定一个主题），而消费者负责订阅主题并进行消费。

主题是一个逻辑上的概念，它还可以细分为多个分区，一个分区只属于单个主题，很多时候也会把分区称为主题分区（Topic-Partition）。同一主题下的不同分区包含的消息是不同的，分区在存储层面可以看作一个可追加的日志（Log）文件，消息在被追加到分区日志文件的时候都会分配一个特定的偏移量（offset）。

![](http://img.bcoder.top/2020.01.26.1/23.png)

如上图所示，主题中有4个分区，消息被顺序追加到每个分区日志文件的尾部。Kafka 中的分区可以分布在不的服务器（broker）上，也就是说，一个主题可以横跨多个 broker，以此来提供比单个 broker 更强大的性能。

**副本**：为分区引入了多副本（Replica）机制，通过增加副本数量可以提升容灾能力。同一分区的不同副本中保存的是相同的消息，副本之间是“一主多从”的关系，其中 leader 副本负责处理读写请求，follower 副本只负责与 leader 副本的消息同步。

![](http://img.bcoder.top/2020.01.26.1/24.png)

#### 3.生产者

一个正常的生产逻辑需要具备以下几个步骤：

> 1. 配置生产者客户端参数及创建相应的生产者实例。
> 2. 构建待发送的消息。
> 3. 发送消息。
> 4. 关闭生产者实例。

```java
    public static void main(String[] args) throws Exception {
        // 1.配置生产者客户端参数及创建相应的生产者实例
        Properties properties = new Properties();
        properties.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");
        properties.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");
        properties.put("bootstrap.servers", "localhost:9092");
        KafkaProducer<String, String> producer = new KafkaProducer<>(properties);
        // 2. 构建待发送的消息
        ProducerRecord<String, String> record = new ProducerRecord<>("topic-demo", "hello, Kafka!");
        // 3.发送消息
        producer.send(record);
        // 4.关闭生产者实例
        producer.close();
    }
```

必要参数配置

- **bootstrap.servers**: 该参数用来指定生产者客户端连接 Kafka 集群所需的 broker 地址清单，具体的内容格式为 host1:port1,host2:port2。

  注意这里并非需要所有的 broker 地址，因为生产者会从给定的 broker 里查找到其他 broker 的信息。建议至少要设置两个以上的 broker 地址信息。

- **key.serializer** 和 **value.serializer**:  broker 端接收的消息必须以字节数组（byte[]）的形式存在。producer在发往 broker 之前需要将消息中对应的 key 和 value 做相应的序列化操作来转换成字节数组。注意这里必须填写序列化器的全限定名，单单指定 StringSerializer 是错误的。

最佳实践

- 在实际使用过程中，诸如`key.serializer`、`max.request.size`、`interceptor.classes`之类的字符串经常由于人为因素而书写错误。为此，我们可以直接使用客户端中的 `org.apache.kafka.clients.producer.ProducerConfig` 类来做一定程度上的预防措施，每个参数在 `ProducerConfig` 类中都有对应的名称。例：

  ```java
  properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG,StringSerializer.class.getName());
  ```

- `KafkaProducer` 是线程安全的，可以在多个线程中共享单个` KafkaProducer` 实例，也可以将 `KafkaProducer` 实例进行池化来供其他线程调用。

  

消息对象 `ProducerRecord`，包含了很多属性

```java
package org.apache.kafka.clients.producer;
public class ProducerRecord<K, V> {
    private final String topic; //主题
    private final Integer partition; //分区号
    private final Headers headers; //消息头部
    private final K key; //键
    private final V value; //值
    private final Long timestamp; //消息的时间戳
    //省略其他成员方法和构造方法
}
```

> **headers**: 消息的头部, 它大多用来设定一些与应用相关的信息，如无需要也可以不用设置。
>
> **key**: 指定消息的键，它不仅是消息的附加信息，还可以用来计算分区号进而可以让消息发往特定的分区。前面提及消息以主题为单位进行归类，而这个 key 可以让消息再进行二次归类。有 key 的消息还可以支持日志压缩的功能。
>
> **value**:  消息体，一般不为空。如果为空，则表示为墓碑消息（tombstone）。



消息发送

创建生产者实例和构建消息之后，就可以开始发送消息了。发送消息主要有三种模式：发后即忘（fire-and-forget）、同步（sync）及异步（async）。

- **发后即忘**： 上述代码`producer.send(record)`就是发后即忘。只管往broker发送，而不关心是否正确到达。这种方式稳定性最高，可靠性也最差。

- **同步**： ` producer.send(record).get()`。实际上 send() 方法本身就是异步的，返回的 Future 对象可以使调用方稍后获得发送的结果。

  ```java
  public Future<RecordMetadata> send(ProducerRecord<K, V> record)
  ```

  执行 send() 方法之后直接链式调用了 get() 方法来阻塞等待 Kafka 的响应，直到消息发送成功，或者发生异常。类似`Future<?>  ExecutorService.submit(Runnable task)`。返回对象`RecordMetadata `包含了当前消息的主题、分区号、分区中的偏移量（offset）、时间戳等元数据信息。

- **异步**： 设置回调接口，例:

  ```java
  producer.send(record, new Callback() {
      /**
      * metadata 与 exception 是互斥的。两个参数有且仅有一个为null。
      */
      @Override
      public void onCompletion(RecordMetadata metadata, Exception exception) {
          if (exception != null) {
              // 异常处理。比如可以将异常记录以便日后分析，也可以做一定的处理来进行消息重发。
              exception.printStackTrace();
          } else {
              // 发送成功。
              System.out.println(metadata.topic() + "-" +
                      metadata.partition() + ":" + metadata.offset());
          }
      }
  });
  ```

  对于同一个分区而言，如果消息 record1 于 record2 之前先发送，那么 KafkaProducer 就可以保证对应的 callback1 在 callback2 之前调用。



异常

主要分为**可重试的异常**和**不可重试的异常**

- **可重试异常**：常见的可重试异常有：`NetworkException`、`LeaderNotAvailableException`等。可以配置重试参数`props.put(ProducerConfig.RETRIES_CONFIG, 10)`

  网络瞬时故障而导致的异常，可以通过重试解决;

  分区的 leader 副本不可用,异常通常发生在 leader 副本下线而新的 leader 副本选举完成之前，重试之后可以重新恢复。

- **不可重试异常**：比如：`RecordTooLargeException` 异常。不会进行任何重试，直接抛出异常。



整个生产者客户端由两个线程协调运行，这两个线程分别为主线程和 Sender 线程。在主线程中由 KafkaProducer 创建消息，然后通过可能的拦截器、序列化器和分区器的作用之后缓存到消息累加器中(双端队列)。Sender 线程负责从 RecordAccumulator 中获取消息并将其发送到 Kafka 中。

![](http://img.bcoder.top/2020.01.26.1/25.png)

拦截器

生产者拦截器既可以用来在消息发送前做一些准备工作，比如按照某个规则过滤不符合要求的消息、修改消息的内容等，也可以用来在发送回调逻辑前做一些定制化的需求，比如统计类工作。实现`org.apache.kafka.clients.producer. ProducerInterceptor `接口。



序列化

生产者需要用序列化器（Serializer）把对象转换成字节数组才能通过网络发送给 Kafka。而在对侧，消费者需要用反序列化器（Deserializer）把从 Kafka 中收到的字节数组转换成相应的对象。

上述例子中，K-V 都使用了`org.apache.kafka.common.serialization.StringSerializer`，我们也可以实现`org.apache.kafka.common.serialization.Serializer`接口，自定义序列化方案。但必须保证producer和consumer一致。



分区器

如果消息 ProducerRecord 中指定了 partition 字段，那么就不需要分区器的作用。如果消息 ProducerRecord 中没有指定 partition 字段，那么就需要依赖分区器，根据 key 这个字段来计算 partition 的值。分区器的作用就是为消息分配分区。

Kafka 中提供的默认分区器是 `org.apache.kafka.clients.producer.internals.DefaultPartitioner`。也可以实现`org.apache.kafka.clients.producer.Partitioner`接口自定义分区器。



#### 4.消费者

Kafka 中的消费是基于拉模式的。消息的消费一般有两种模式：推模式和拉模式。推模式是服务端主动将消息推送给消费者，而拉模式是消费者主动向服务端发起请求来拉取消息。

应用程序可以通过 KafkaConsumer 来订阅主题，并从订阅的主题中拉取消息。在 Kafka 的消费理念中有一层消费组（Consumer Group）的概念，每个消费者都有一个对应的消费组。当消息发布到主题后，只会被投递给订阅它的**每个消费组中的一个**消费者。

![](http://img.bcoder.top/2020.01.26.1/26.png)

如上图所示，某个主题中共有4个分区（Partition）：P0、P1、P2、P3。有两个消费组A和B都订阅了这个主题，消费组A中有4个消费者（C0、C1、C2和C3），消费组B中有2个消费者（C4和C5）。按照 Kafka 默认的规则，最后的分配结果是消费组A中的每一个消费者分配到1个分区，消费组B中的每一个消费者分配到2个分区，两个消费组之间互不影响。每个消费者只能消费所分配到的分区中的消息。换言之，每一个分区只能被一个消费组中的一个消费者所消费。

分配逻辑都是基于默认的分区分配策略进行分析的，可以通过消费者客户端参数 `partition.assignment.strategy` 来设置消费者与订阅主题之间的分区分配策略。



一般有两种消息投递模式：点对点（P2P，Point-to-Point）模式和发布/订阅（Pub/Sub）模式。

在kafka中，同时支持这两种模式：

- 如果所有的消费者都隶属于同一个消费组，那么所有的消息都会被均衡地投递给每一个消费者，即每条消息只会被一个消费者处理，这就相当于P2P模式的应用。
- 如果所有的消费者都隶属于不同的消费组，那么所有的消息都会被广播给所有的消费者，即每条消息会被所有的消费者处理，这就相当于Pub/Sub模式的应用。

消费组是一个逻辑上的概念，每一个消费者只隶属于一个消费组。每一个消费组都会有一个固定的名称，消费者在进行消费前需要指定其所属消费组的名称，这个可以通过消费者客户端参数 group.id 来配置。



一个正常的生产逻辑需要具备以下几个步骤：

> 1. 配置消费者客户端参数及创建相应的消费者实例
> 2. 订阅主题
> 3. 拉取消息并消费
> 4. 提交消费位移
> 5. 关闭消费者实例

```java
    public static void main(String[] args) {
        // 配置消费者客户端参数及创建相应的消费者实例
        Properties props = new Properties();
        props.put("key.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");
        props.put("value.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");
        props.put("bootstrap.servers", "localhost:9092");
        // 消费者隶属的消费组的名称，默认值为“”。如果设置为空，则会报出异常。这个参数需要设置成具有一定的业务意义的名称
        props.put("group.id", "group.demo");
        props.put("client.id", "consumer.client.id.demo");
        KafkaConsumer<String, String> consumer = new KafkaConsumer<>(props);
        // 订阅主题.一个或多个
        consumer.subscribe(Arrays.asList("topic-demo"));
        try {
            while (true) {
                // 拉取消息并消费
                ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(1000));
                for (ConsumerRecord<String, String> record : records) {
                    System.out.println(record);
                    //do something to process record.
                }
            }
        } catch (Exception e) {
            e.printStackTrace();
        } finally {
            // 关闭消费者实例
            consumer.close();
        }
    }
```



消费者可以直接订阅一个或多个主题，也支持正则方式匹配：

```java
consumer.subscribe(Pattern.compile("topic-.*"));
```

消费者也直接订阅某些主题的特定分区：

```java
// 只订阅 topic-demo 主题中分区编号为0的分区
consumer.assign(Arrays.asList(new TopicPartition("topic-demo", 0)));
```

通过 subscribe() 方法订阅主题具有消费者自动再均衡的功能，在多个消费者的情况下可以根据分区分配策略来自动分配各个消费者与分区的关系。当消费组内的消费者增加或减少时，分区分配关系会自动调整，以实现消费负载均衡及故障自动转移。

通过 assign() 方法订阅分区时，是不具备消费者自动均衡的功能的。



消费位移与消费提交控制

在 Kafka 中默认的消费位移的提交方式是自动提交，这个由消费者参数 enable.auto.commit 配置，默认值为 true。当然这个默认的自动提交不是每消费一条消息就提交一次，而是定期提交，这个定期的周期时间由客户端参数auto.commit.interval.ms 配置，默认值为5秒。

![](http://img.bcoder.top/2020.01.26.1/27.png)

参考上图中的消费位移，x表示某一次拉取操作中此分区消息的最大偏移量，假设当前消费者已经消费了x位置的消息，那么我们就可以说消费者的消费位移为x，图中也用了 lastConsumedOffset 这个单词来标识它。

当前消费者需要提交的消费位移并不是x，而是x+1，对应于上图中的 position，它表示下一条需要拉取的消息的位置。

`KafkaConsumer` 类提供了 position 和 committed 两个方法来分别获取上面所说的 position 和 committed offset 的值。

```
public long position(TopicPartition partition)
public OffsetAndMetadata committed(TopicPartition partition)
```

对于位移提交的具体时机的把握很有讲究，有可能会发生消息丢失或重复消费的现象。

![](http://img.bcoder.top/2020.01.26.1/28.png)

- **消息丢失**: 当前一次 poll() 操作所拉取的消息集为 [x+2, x+7]，x+2 代表上一次提交的消费位移，说明已经完成了 x+1 之前（包括 x+1 在内）的所有消息的消费，x+5 表示当前正在处理的位置。如果拉取到消息之后就进行了位移提交，即提交了 x+8，那么当前消费 x+5 的时候遇到了异常，在故障恢复之后，我们重新拉取的消息是从 x+8 开始的。也就是说，x+5 至 x+7 之间的消息并未能被消费，如此便发生了消息丢失的现象。
- **重复消费**: 位移提交的动作是在消费完所有拉取到的消息之后才执行的，那么当消费 x+5 的时候遇到了异常，在故障恢复之后，我们重新拉取的消息是从 x+2 开始的。也就是说，x+2 至 x+4 之间的消息又重新消费了一遍，故而又发生了重复消费的现象。



**手动提交 **使得对消费位移的管理控制更加灵活，需要将消费者参数 enable.auto.commit 配置为 false。它分为**同步提交** 和**异步提交**

- **同步提交**：对应`KafkaConsumer.commitSync() `。

  ```java
   ConsumerRecords<String, String> records = consumer.poll(1000);
     for (ConsumerRecord<String, String> record : records) {
         // 业务逻辑
     }
   consumer.commitSync();
  ```

  

- **异步提交**：对应`KafkaConsumer.commitAsync()`。

  ```java
      ConsumerRecords<String, String> records = consumer.poll(1000);
      for (ConsumerRecord<String, String> record : records) {
          // 业务逻辑
      }
      consumer.commitAsync(new OffsetCommitCallback() {
          @Override
          public void onComplete(Map<TopicPartition, OffsetAndMetadata> offsets,
                                 Exception exception) {
              if (exception == null) {
                  System.out.println(offsets);
              }else {
                  log.error("fail to commit offsets {}", offsets, exception);
              }
          }
      });
  ```

如果位移提交失败的情况经常发生，那么说明系统肯定出现了故障，在一般情况下，位移提交失败的情况很少发生。



控制或关闭消费

在有些应用场景下我们可能需要暂停某些分区的消费而先消费其他分区，当达到一定条件时再恢复这些分区的消。`KafkaConsumer` 中使用 pause() 和 resume() 方法来分别实现暂停某些分区在拉取操作时返回数据给客户端和恢复某些分区向客户端返回数据的操作。

```java
public void pause(Collection<TopicPartition> partitions)
public void resume(Collection<TopicPartition> partitions)
```



消费的消息`ConsumerRecord`，包含了很多属性：

```java
public class ConsumerRecord<K, V> {
    private final String topic;		// 主题
    private final int partition;	// 分区号
    private final long offset;		// 消息在所属分区的偏移量
    private final long timestamp;	
    // 表示时间戳的类型。CreateTime和LogAppendTime，分别代表消息创建的时间戳和消息追加到日志的时间戳。
    private final TimestampType timestampType;
    private final int serializedKeySize;    // key序列化之后的大小
    private final int serializedValueSize;  // value序列化之后的大小
    private final Headers headers;	        //头部内容
    private final K key;
    private final V value;		     // 一般是业务要读取的对象
    private volatile Long checksum;  //  CRC32 的校验值
	    //省略若干方法
}
```



消费者多线程

`KafkaProducer `是线程安全的，然而`KafkaConsumer` 却是非线程安全的(定义了一个 acquire() 方法，用来检测当前是否只有一个线程在操作，若有其他线程正在操作则会抛出` ConcurrentModifcationException` 异常)。

`KafkaConsumer`非线程安全并不意味着我们在消费消息的时候只能以单线程的方式执行，我们可以通过一下方式来实现多线程消费：**线程封闭** 和 **消息处理多线程**。

线程封闭，即为每个线程实例化一个 KafkaConsumer 对象：

![](http://img.bcoder.top/2020.01.26.1/29.png)

消息处理多线程：减少TCP连接并具有横向扩展能力。

![](http://img.bcoder.top/2020.01.26.1/30.png)

#### 5 主题与分区

主题和分区是 Kafka 的两个核心概念，主题作为消息的归类，可以再细分为一个或多个分区，分区也可以看作对消息的二次归类。分区的划分不仅为 Kafka 提供了可伸缩性、水平扩展的功能，还通过多副本机制来为 Kafka 提供数据冗余以提高数据可靠性。分区可以有一至多个副本，每个副本对应一个日志文件，每个日志文件对应一至多个日志分段，每个日志分段还可以细分为索引文件、日志存储文件和快照文件等。

![](http://img.bcoder.top/2020.01.26.1/31.png)

相关命令



在一个包含3个broker节点的集群上利用以下命令创建主题

```bash
# 创建了一个分区数为4、副本因子为2的主题 "topic-create"
./kafka-topics.sh --zookeeper localhost:2181/kafka --create --topic topic-create --partitions 4 --replication-factor 2

```

在执行完脚本之后，Kafka 会在 log.dir 或 log.dirs 参数所配置的目录下创建相应的主题分区。

```bash
# node-1
ls -al /tmp/kafka-logs/ | grep topic-create
drwxr-xr-x   2 root root 4096 Sep  8 15:54 topic-create-0
drwxr-xr-x   2 root root 4096 Sep  8 15:54 topic-create-1

# node-2
ls -al /tmp/kafka-logs/ |grep topic-create
drwxr-xr-x   2 root root   4096 Sep  8 15:49 topic-create-1
drwxr-xr-x   2 root root   4096 Sep  8 15:49 topic-create-2
drwxr-xr-x   2 root root   4096 Sep  8 15:49 topic-create-3

# node-3
ls -al /tmp/kafka-logs/ |grep topic-create
drwxr-xr-x   2 root root 4096 Sep  8 07:54 topic-create-0
drwxr-xr-x   2 root root 4096 Sep  8 07:54 topic-create-2
drwxr-xr-x   2 root root 4096 Sep  8 07:54 topic-create-3
```

三个broker节点一共创建了8个文件夹（分区数4 * 副本因子2），每个副本与日志一一对应，对应命名` <topic>-<partition>`

![](http://img.bcoder.top/2020.01.26.1/32.png)

#### 6. 幂等性

在很多要求严格的场景下，例如用Kafka处理交易数据，`Exactly Once`语义是必须的。我们可以通过让下游系统具有幂等性来配合Kafka的`At Least Once`语义来间接实现`Exactly Once`。但是：

- 该方案要求下游系统支持幂等操作
- 实现门槛相对较高，需要用户对Kafka的工作机制非常了解



Kafka引入了`Producer ID`（即`PID`）和`Sequence Number`。每个新的Producer在初始化的时候会被分配一个唯一的PID，该Producer发送数据的每个`<Topic, Partition>`都对应一个从0开始单调递增的`Sequence Number`。

Broker端也会为每个`<PID, Topic, Partition>`维护一个序号，并且每次Commit一条消息时将其对应序号递增。对于接收的每条消息，如果其序号比Broker维护的序号（即最后一次Commit的消息的序号）大一，则Broker会接受它，否则将其丢弃。

- 如果消息序号比Broker维护的序号大一以上，说明中间有数据尚未写入，也即乱序，此时Broker拒绝该消息，Producer抛出`InvalidSequenceNumber`
- 如果消息序号小于等于Broker维护的序号，说明该消息已被保存，即为重复消息，Broker直接丢弃该消息，Producer抛出`DuplicateSequenceNumber`

这样就保证了单个Producer对于同一个`<Topic, Partition>`的`Exactly Once`语义。



#### 7.事务消息



**事务消息**，kafka 中的事务特性主要用于一下两种场景：

- **生产者发送多条消息可以封装在一个事务中，形成一个原子操作。**多条消息要么都发送成功，要么都发送失败。
- **read-process-write模式：将消息消费和生产封装在一个事务中，形成一个原子操作。** 在一个应用处理中，服务需要从上游接收消息，经过处理后，再将消息发送到下游。

> 当事务中仅仅存在Consumer消费消息的操作时，它和Consumer手动提交Offset并没有区别。因此单纯的消费消息并不是Kafka引入事务机制的原因，单纯的消费消息没有必要存在于一个事务中。

`KafkaProducer`类为我们提供了用于事务操作的接口：

```java
    // 初始化事务
    public void initTransactions();
    // 开启事务
    public void beginTransaction() throws ProducerFencedException ;
    // 在事务内提交已经消费的偏移量
    public void sendOffsetsToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets, 
                                         String consumerGroupId) throws ProducerFencedException ;
    // 提交事务。使得Producer写入的数据对下游Consumer可见
    public void commitTransaction() throws ProducerFencedException;
    // 丢弃事务。将Producer写入的数据标记为Aborted状态，如果下游的Consumer将isolation.level设置为READ_COMMITTED，则它读到被Abort的消息后直接将其丢弃。
    public void abortTransaction() throws ProducerFencedException ;
```



场景一：

```java
// message1 和 message2 要么都发送成功，要么都发送失败
producer.initTransactions();
producer.beginTransaction();
producer.send("outputTopic", "message1");
producer.send("outputTopic", "message2");
producer.commitTransaction();
```

场景二：

```java
// read-process-write模式，即先消费，再处理，最后投入到生产
producer.initTransactions();
while (true) {
  ConsumerRecords records = consumer.poll(Long.MAX_VALUE);
  producer.beginTransaction();
  for (ConsumerRecord record : records)
    // 此处可进行业务逻辑处理，然后将处理结果提交给下游
    producer.send(producerRecord(“outputTopic”, record));
  // 提交已经消费的偏移量
  producer.sendOffsetsToTransaction(currentOffsets(consumer), group);  
  producer.commitTransaction();
}
```



**注意** ： 不要把操作db的业务逻辑跟操作消息当成是一个事务。db的事务操作是CRUD，对应的数据源是db(例如mysql)，而操作消息是一系列生产和消费，对应的数据源是kafka，它们是两个独立的事务。

#### 8.用户权限

```bash
#  为用户 alice 在 test（topic）上添加读写的权限
kafka-acls.sh --authorizer-properties zookeeper.connect=ip:2181 --add --allow-principal User:alice --operation Read --operation Write --topic test

# 对于 topic 为 test 的消息队列，拒绝来自 ip 为192.168.1.100账户为 zhangsan 进行 read 操作，其他用户都允许
/kafka-acls.sh --authorizer-properties zookeeper.connect=ip:2181 --add --allow-principal User:* --allow-host * --deny-principal User:zhangsan --deny-host 192.168.1.100 --operation Read --topic test

# 为 zhangsan 和 alice 添加all，以允许来自 ip 为192.168.1.100或者192.168.1.101的读写请求
kafka-acls.sh --authorizer-properties zookeeper.connect=ip:2181 --add --allow-principal User:zhangsan --allow-principal User:alice --allow-host 192.168.1.100 --allow-host 192.168.1.101 --operation Read --operation Write --topic test

# 列出 topic 为 test 的所有权限账户
kafka-acls.sh --authorizer-properties zookeeper.connect=ip:2181 --list --topic test

```



#### 9.重要参数

生产者重要参数：

- **acks**: 这个参数用来指定分区中必须要有多少个副本收到这条消息，之后生产者才会认为这条消息是成功写入的。默认1。
- **max.request.size**: 这个参数用来限制生产者客户端能发送的消息的最大值，默认值为1MB。(与其它参数存在联动，不建议修改)
- **retries** 和**retry.backoff.ms**：retries 参数用来配置生产者重试的次数，默认值为0，即在发生异常的时候不进行任何重试动作。 retry.backoff.ms 设定两次重试之间的时间间隔，默认100。
- **compression.type**: 这个参数用来指定消息的压缩方式，默认值为“none”，即默认情况下，消息不会被压缩。消息压缩是一种使用时间换空间的优化方式，如果对时延有一定的要求，则不推荐对消息进行压缩。
- **request.timeout.ms**: 这个参数用来配置 Producer 等待请求响应的最长时间，默认值为30000（ms）

消费者重要参数：

- **fetch.min.bytes**:  该参数用来配置 Consumer 在一次拉取请求中能从 Kafka 中拉取的最小数据量，默认值为1（B）。
- **fetch.max.bytes**:  该参数与 fetch.min.bytes 参数对应，它用来配置 Consumer 在一次拉取请求中从Kafka中拉取的最大数据量，默认值为52428800（B），也就是50MB。
- **request.timeout.ms**:  这个参数用来配置 Consumer 等待请求响应的最长时间，默认值为30000（ms）。

更多配置请参考 [Kafka配置](<http://kafka.apache.org/documentation/#configuration>)





## 总结

#### 1.中间件对比

以下是RabbitMQ，RocketMQ，Kafka三者之间的对比:

| 中间件       | RabbitMQ       | RocketMQ                                                     | Kafka                                                        |
| ------------ | -------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 协议和规范   | AMQP           | Pull model, support TCP，JMS， OpenMessaging                 | Pull model, support TCP                                      |
| 开发语言     | Erlang         | Java                                                         | Scala+Java                                                   |
| 单机吞吐量   | 万级           | 万级                                                         | 十万级                                                       |
| 可用性       | 一般（主从）   | 非常高（分布式）                                             | 非常高（分布式）                                             |
| 社区活跃度   | 高             | 中                                                           | 高                                                           |
| 文档与API    | 高             | 高                                                           | 高                                                           |
| 消息写入性能 | 较好           | 很好                                                         | 非常好                                                       |
| 事务消息     | 支持           | 支持+事务反查                                                | 支持                                                         |
| 可靠性       | 高             | 高                                                           | 较高                                                         |
| 主从切换     |                | 不支持自动切换。master失效以后不能向其发送信息，consumer大概30s可以感知此事件，此后从slave消费；如果master无法恢复，异步复制时可能出现部分信息丢失 | 自动切换。N个副本，允许N-1个失效；master失效以后自动从isr中选择一个主； |
| 设计定位     | 可靠消息传输。 | 非日志的可靠消息传输。例如：订单，交易，充值，流计算，消息推送，日志流式处理，binglog分发等 | 系统间的数据流管道，实时数据处理。例如：常规的消息系统、网站活性跟踪，监控数据，日志收集、处理等 |



选择Kafka的原因:

​	a.  集群部署架构好，具有高性能，高可用，高伸缩性，时间复杂度为O(1)的消息持久化能力和特定消息的读取能力；

​    b. 开发语言为Java系，而且社区活跃度高，文档资料非常齐全， 易于问题定位和排查；

​    c. 契合目前项目中的前端消息推送需求，各微服务的统一日志收集需求；

​    d. 同时支持离线数据处理和实时数据处理，应用场景更加广阔，被多家[公司](<https://cwiki.apache.org/confluence/display/KAFKA/Powered+By>)和多个开源项目使用。它不仅仅是个消息中间件，在活动数据流，运营数据流，CDC等中也承担的重要角色。



#### 2.应用场景

- 结合Websocket，实现前端消息的实时推送

![](http://img.bcoder.top/2020.01.26.1/33.png)



> 1. 用户的请求发送到代理对象
> 2. 代理对象通过负载均衡策略将请求发送到某个业务节点
> 3. 收到请求的业务节点进行业务处理以后，生产出对应topic的消息，并将其发布到kafka集群
> 4. kafka向订阅了该topic消息的所有业务节点进行广播
> 5. 各业务节点通过与前端建立的websocket进行实时消息推送



- 搭建ELK日志管理平台，进行数据收集，存储，索引，检索，统计分析及可视化

单个应用被拆分为多个应用，每个应用集群部署进行负载均衡。如果某项业务发生系统错误，开发或运维人员还是以过往单体应用方式登录一台一台登录服务器查看日志来定位问题效率会非常低。这时日志管理平台的建设就很重要。

![](http://img.bcoder.top/2020.01.26.1/34.png)

主要处理步骤如下：

> 1. 通过Logstash去收集每台服务器日志文件，然后传输到Kafka；
> 2. 另一个Logstash从KafKa读取日志存储到elasticsearch中创建索引;
> 3. 通过Kibana展示给开发者或运维人员进行分析。



- DB数据同步到数据仓库

  在数据仓库建模中，未经任何加工处理的原始业务层数据，称之为ODS(Operational Data Store)数据。常见的ODS数据有**业务日志数据（Log）**和**业务DB数据**两类。对于业务DB数据来说，从关系型数据库的业务数据进行采集，然后导入到数据仓库中，是进行数据仓库生产的重要环节。

  

  一般方案是：直连DB去select表中数据  →  将获得的数据存到本地文件作为中间存储 → 将中间文件load到数据仓库。

![](http://img.bcoder.top/2020.01.26.1/35.png)

但该中方案存在着一些问题：

- 随意业务或数据的增长，select  → save → load 这种数据流花费的时间会很长，很可能无法满足下游数仓生产的时间要求。
- 直接从DB中select大量数据，对DB的影响会非常大，容易造成慢查询，影响正常线上业务。



新方案：CDC+Merge。

- CDC：Change Data Capture，意为“变动数据捕获”。核心思想是监测并捕获数据库的变动（包括数据或数据表的插入，更新，删除等），将这些变更按发生的顺序完整记录下来，写入到消息中间件中以供其他服务进行订阅及消费。
- binlog: 是一个二进制格式的文件，用于记录用户对数据库**更新的SQL语句**信息，例如更改数据库表和更改内容的SQL语句都会记录到binlog里，但是对库表等内容的**查询不会记录**。

![](http://img.bcoder.top/2020.01.26.1/36.png)

主要步骤：

> 1. 使用cannal从DB实时拉取binlog，适当解析后，将其push到kafka上。
> 2. 使用camus，每小时将kafka上的binlog数据拉取到warehouse。
> 3. 对每张ODS表，首先需要一次性制作快照（Snapshot），把DB里的存量数据读取到warehouse里，该过程底层采用直连DB去Select数据的方式。注意，该过程只执行一次。
> 4. 对每张ODS表，每天基于存量数据和当天增量产生的Binlog做Merge，从而还原出业务数据。



- 更多CDC的使用

  - 异构数据库之间的数据同步或备份 :在 MySQL，PostgreSQL，MongoDB 等等数据库之间互相同步数据，或者把这些数据库的数据同步到 Elasticsearch 里以供全文搜索，当然也可以基于 CDC 对数据库进行备份。而数据分析系统可以通过订阅感兴趣的数据表的变更，来获取所需要的分析数据进行处理，不需要把分析流程嵌入到已有系统中，以实现解耦。

  ![](http://img.bcoder.top/2020.01.26.1/37.png)

  - 微服务之间共享数据状态: 微服务之间信息共享一直比较复杂，CDC 也是一种可能的解决方案，微服务可以通过 CDC 来获取其他微服务数据库的变更，从而获取数据的状态更新，执行自己相应的逻辑。

在整个 CDC 里，Kafka 会作为核心的数据交换组件，或者你可以把它称为数据总线，kafka 集群的健壮性和吞吐量能够支撑海量数据的 pub/sub，并且能够将写入的数据持久化一段时间，发布服务将数据库任何数据变动写入 Kafka，由不同的消费者在上面同时进行订阅和消费。

![](http://img.bcoder.top/2020.01.26.1/38.png)
