# 快手高级开发社招

## 一面

### Spring 原理、Spring IOC、AOP

+ 这个问题 最好可以多说一点，比如 对于IOC，不妨把Bean 如何加载、如何初始化以及如何注册到IOC容器中的详细过程说一下， 涉及BeanDefinition、BeanFactory也深入细节聊一下。

### 一个请求过来在Spring中发生了哪些事情

+ 这个问题不妨把一个请求过来在TCP层面上建立连接、操作系统如何处理连接、Web容器接收到连接对象后做了哪些事情、Spring 如何对接收到的请求进行处理都说一下，当然最终还是落在Spring 容器内部如何处理一个请求，这个过程一定要说清楚，需要体现细节。在说前面的内容的时候，可以放心面试官不会打断你。

### 手写一个栈，实现 push，pop方法，以及 max(获取最大的元素) 方法，要求时间复杂度为 O(1)

+ 这是一个考察数据结构的问题，一方面需要候选⼈对数据结构有所了解，一方面也需要候选人对代码有驾驭能力(毕竟要手写代码)。面试官会给一定的时间，在这段时间里，面试官不会打扰你，并尽可能为你提供方便，比如，签字笔不好用，面试官会帮你更换。据我个人经验，凡是面对需要写代码的问题，都不要急着放弃，静下心来，仔细思考，都是可以写得不错的。如果没能写出来，面试官会问你实现思路，如果你的思路很优化，一样可以过了这道题，但是前提是：你的代码不能一行都不写。

  对于数据结构的考察的话，我建议看一下jdk中对于List、Stack、Tree、Set的实现，比如，至少你要知道，如果让你实现一个单链表，你会如何实现；比如，你可能会定义一个Node节点，里面有当前节点的key和value，还有对于下一个节点的引用。如果熟悉jdk对于各种数据结构的实现，这道题是很容易过的。

### JVM内存结构

+ 这个问题需要你能画出JVM内存结构的图，画出方法区、堆、程序计算器、虚拟机栈、本地方法栈，并说出每一个部分具体是什么作用，比如，哪些是线程共享的，哪些是线程独享的，哪些地方存放了什么数据，为什么会这样存放，哪些虚拟机参数对这些空间大小是有影响的，可以如何配置。这些都比较常规

### 手写一个单例

+ 这个基本上大多数公司都会考察的。要写一个基于懒汉式的双重检测的单例。单例有三个比较关键的点，一是私有构造方法，避免外部new出对象；二是保证唯一性；三是提供一个全局访问点。

  另外，懒汉式双重检测的实现方式 有三点需要注意的地方，一是 全局访问点必须是静态的，外界使用可以通过类直接调用，二是在进入锁之后还需要校验，三是保存单例对象的私有变量一定要用volatile修饰，这个地方可以多说一些，比如volatile防止指令重排序，保证内存可见性(JVM层面和CPU层面可以分别说)。volatile 这个地方能说的东西还是很多的，基本上可以与面试官再聊二十分钟了。

### HashMap相关

+ 对于 HashMap 其实一般高级岗位及以上不再会问这个东西了，一旦问了，肯定不是让你只说一下数组+链表的。对于它的实现，不同版本实现方式不一样。

  在jdk1.8之后，HashMap除了数组+链表之外，引用了红黑树。那么好了，你需要说明 对于 引用了红黑树的 HashMap 如何put一个元素，以及链表是在何时转化为红黑树的。比如，首先需要知道这个元素落在哪一个数组里，获取hashcode后并不是对数组长度取余来确定的，而是高低位异或求与来得到的。这个地方首先得知道异或求与是做什么样的运算的。

  之后说一下在HashMap中的实现，比如hashcode无符号右移16位后和原hashcode做异或运算，这相当于把hashcode的高16位拿过来和hashcode的低16位做异或运算，因为无符号右移后前面说的16位都补零，这就是前面说的 "高低位异或“，进而是“求与”，和谁求与呢，和数组长度减1 求与。说到这里起码能够证明你是看过源码的，接下来说说你的思考，比如我们知道对于hashmap 初始化容量决定了数组大小，一般我们对于数组这个初始容量的设置是有规律的，它应该是 2^n 。这个初始容量的设置影响了HashMap的效率，那又涉及到影响HashMap效率的主要因素，比如初始容量和负载因子。

  当已用数组达到容量与负载因子的乘积之后会进行一个rehash的过程，这个地方涉及到的如何rehash及各种算法如果有时间也是可以说的，没有时间不说也没有关系。回到刚才说的 2^n, 可以说说它为什么是2^n。

  当我们说什么东西为什么是这样的时候，我们一般从两个⻆度考虑，一个是：这样做有什么好处，另一个是：不这样做有什么坏处。我们刚才说到“求与”这个过程，如果不是 2^n, 会导致较多的哈希碰撞(具体原因可以自己分析一下或者百度一下)，这个会影响HashMap的效率。说完上面这些，既表明你看过源码，又表明你有自己的思考了，当然也可以进一步说说它是在什么条件下以及如何进行扩容的（如果时间允许，并且面试官也有耐心继续听下去）。

  对于put操作，这才只是第一步，找到数组的位置，接下来 要看这个位置也没有元素，如果没有，直接放进去就可以，如果有，要看怎么放进去，jdk1.8中 对于HashMap的实现中，是基于Node(链表节点) 和TreeNode(红黑树节点) 的，当然它们继承了Entry。

  那么，如果数组当前位置已经有了元素，就得知道这个元素是链表的节点还是红黑树的节点，以便进一步确认接下来要put的元素是以链表的方式插入，还是以红黑树的方式插入，这个地方在源码中进入了一个类型的判断，如果是链表的节点，就以链表的方式把要put的节点插入到next为null的节点上，如果是红黑树的节点，就要以红黑树的方式插入一个节点。

  接下来其实不是考察的重点，但是也可以说说，就是:

  (1) 为什么要引入红黑树，

  (2)如何在红黑树中插入一个节点。对于这两个问题，首先，引入红黑树的好处是为了
  提高查询效率，要说出O(log2(n))，但是在提高查找效率的同时 也在插入的时候更加耗时，那可以说一下为什么更加耗时，自然带出第二个问题，如何在红黑树中插入一个节点，比如 当插入一个节点的时候我们会默认它是红色的(这个地方可以结合红黑树特点说一下 我们为什么默认它是红色的，从黑色高度以及相邻两节点不同为红色入手)，插入后如果父节点是黑色的 就不需要动了，但假如是红色的，就需要进行左旋和右旋操作，如果很了解，可以细说左旋右旋如何实现，如果不是很了解，到此为止也ok。

  说到这里，我们忽略了一个重要的点，就是链表转换为红黑树的条件，说出链表长度到8(相当于红黑树开始第四层) 以及 数组大小达到64就已经够了，也可以进一步说一下 链表是如何转换为红黑树的。说完也可以说一下 ConcurrentHashMap中也是一样的，然后接下来就引入对ConcurrentHashMap的理解，⽐如 在什么地⽅会涉及到线程安全问题 以及ConcurrentHashMap是如何解决的，说说CAS，说完CAS再说说AQS，自由发挥吧。

### JVM四种引入类型

+ 这个问题比较简单，强引入、弱引入、软引入、虚引入，说一下它们各自的特点和GC对它们的不同处理方式，再说一下常用的应用场景或者jdk的实现中对它们的使用，比如，ThreadLocal 的静态内部类ThreadLocalMap，它的Key是弱引用的，也可以说一下 在你的理解中 为什么它是弱引用的，假如不是会怎么样。

### SpringBoot 启动过程

+ 这个主要是从它基于Spring的事件发布和监听机制开始说起 就没什么问题。

## 二面

### 类加载过程

+ 加载 链接 初始化，链接又分为验证准备和解析，每一个阶段是做了什么要说清楚。Object a = new Object()；这行代码做了哪些事情，需要从类加载开始说起，这个相当于上一问题的延续，所以一定要清楚每一个环节做了哪些事情的，否则这个问题不可能说清楚。

  说完类加载的过程，再说一下开辟内存空间、初始化内存空间以及把内存地址赋值给变量a，接下来可以进一步说一下JVM或者CPU层面对指令的优化，以及在某些时刻我们需要避免它做这样的优化，比如在单例中我们的实例需要用volatile修饰避免指令重排序(可以说一下在new一个对象的过程中如果指令重排序了会导致什么结果)。

### maven的熟练程度

+ 有哪些类型

### Linux命令⾏的熟练程度

+  ${} 和 $() 区别

### 消息队列的熟练程度

+ Kafka分区，如何分区 等等(因为我过往项⽬经验中写了kafka，所以才会被问及，如果写了其他消息队列，也可能会被问及)

### Netty

+ 从NIO开始说 肯定是没错的，再说说Netty的实现⽅式，以及它除了IO之外还⼲了哪些事情。

## 三面

### 根据过往项目经验依次介绍业务

+ 这就需要在面试之前把自己的做过的项目好好总结一下，它们主要做的业务是什么，解决了什么问题，架构是什么样的，以及你在其中做了哪些⼯作。这个地方一定要准备充分，少要能扛得住面试官三连问。否则会被认 你不太清楚你们之前做的到底是什么，那你在业务能力方便可能是不太match的。

### 你有什么问题想问面试官的

+ 这个地方因人而异，但无论怎样，都不要什么都不问，至少你要表现一点对于岗位的兴趣吧。如问一下公司业务，团队构成，技术栈，以及你所应聘的这个岗位大概做哪些工作。

## 四面

HR面试。这一轮可以说是斗智斗勇的一个环节，会考察到些软技能、个人成长、职业素质，也会问一下期望薪资。







# 京东18届一年半经验社招

## ZooKeeper

### CAP定理

+ 一个分布式系统不可能同时满足以下三种,一致性（C:Consistency）,可用性（A:Available）,分区容错性（P:Partition Tolerance）. 在此ZooKeeper保证的是CP，ZooKeeper不能保证每次服务请求的可用性，在极端环境下，ZooKeeper可能会丢弃一些请求，消费者程序需要重新请求才能获得结果。 另外在进行leader选举时集群都是不可用，所以说，ZooKeeper不能保证服务可用性。（Base理论CA强一致性和最终一致性）
+ 推荐阅读
  + [谈谈分布式系统的CAP理论](https://zhuanlan.zhihu.com/p/33999708)
  + [CAP理论中的P到底是个什么意思？](https://www.zhihu.com/question/54105974)
  + [分布式理论(二) - BASE理论](https://juejin.im/post/5b2663fcf265da59a401e6f8)

### ZAB协议

+ ZAB协议包括两种基本的模式：崩溃恢复和消息广播。当整个 Zookeeper 集群刚刚启动或者Leader服务器宕机、重启或者网络故障导致不存在过半的服务器与 Leader 服务器保持正常通信时，所有服务器进入崩溃恢复模式，首先选举产生新的 Leader 服务器，然后集群中 Follower 服务器开始与新的 Leader 服务器进行数据同步。 当集群中超过半数机器与该 Leader 服务器完成数据同步之后，退出恢复模式进入消息广播模式，Leader 服务器开始接收客户端的事务请求生成事物提案来进行事务请求处理。
+ 推荐阅读:[看大牛如何分析Zookeeper ZAB 协议](https://juejin.im/post/5b924b0de51d450e9a2de615)

### Leader选举算法和流程

+ FastLeaderElection(默认提供的选举算法): 目前有5台服务器，每台服务器均没有数据，它们的编号分别是1,2,3,4,5,按编号依次启动，它们的选择举过程如下： (1)服务器1启动，给自己投票，然后发投票信息，由于其它机器还没有启动所以它收不到反馈信息，服务器1的状态一直属于Looking。 (2)服务器2启动，给自己投票，同时与之前启动的服务器1交换结果，由于服务器2的编号大所以服务器2胜出，但此时投票数没有大于半数，所以两个服务器的状态依然是LOOKING。 (3)服务器3启动，给自己投票，同时与之前启动的服务器1,2交换信息，由于服务器3的编号最大所以服务器3胜出，此时投票数正好大于半数，所以服务器3成为leader，服务器1,2成为follower。 (4)服务器4启动，给自己投票，同时与之前启动的服务器1,2,3交换信息，尽管服务器4的编号大，但之前服务器3已经胜出，所以服务器4只能成为follower。 (5)服务器5启动，后面的逻辑同服务器4成为follower。
+ 推荐阅读:[【分布式】Zookeeper的Leader选举](https://www.cnblogs.com/leesf456/p/6107600.html)

## Redis

### Redis的应用场景

+ (1)缓存 (2)共享Session (3)消息队列系统 (4)分布式锁
+ 推荐阅读:[Redis常见的应用场景解析](https://zhuanlan.zhihu.com/p/29665317)

### 单线程的Redis为什么快

+ (1)纯内存操作 (2)单线程操作，避免了频繁的上下文切换 (3)合理高效的数据结构 (4)采用了非阻塞I/O多路复用机制

### Redis 的数据结构及使用场景（必考）

+ (1)String字符串:字符串类型是 Redis 最基础的数据结构，首先键都是字符串类型，而且 其他几种数据结构都是在字符串类型基础上构建的，我们常使用的 set key value 命令就是字符串。常用在缓存、计数、共享Session、限速等。

   (2)Hash哈希:在Redis中，哈希类型是指键值本身又是一个键值对 结构，形如value={{field1，value1}，...{fieldN，valueN}}，添加命令：hset key field value。哈希可以用来存放用户信息，比如实现购物车

   (3)List列表（双向链表）:列表（list）类型是用来存储多个有序的字符串。可以做简单的消息队列的功能。

   (4)Set集合：集合（set）类型也是用来保存多个的字符串元素，但和列表类型不一 样的是，集合中不允许有重复元素，并且集合中的元素是无序的，不能通过 索引下标获取元素。利用 Set 的交集、并集、差集等操作，可以计算共同喜好，全部的喜好，自己独有的喜好等功能。

   (5)Sorted Set有序集合（跳表实现）：Sorted Set 多了一个权重参数 Score，集合中的元素能够按 Score 进行排列。可以做排行榜应用，取 TOP N 操作。

### zset跳表的数据结构（必考）

+ [Redis 为什么用跳表而不用平衡树？](https://juejin.im/post/57fa935b0e3dd90057c50fbc)

### Redis的数据过期策略（必考）

+ Redis 中数据过期策略采用定期删除+惰性删除策略:
  +  (1)定期删除策略：Redis 启用一个定时器定时监视所有的 key，判断key是否过期，过期的话就删除。这种策略可以保证过期的 key 最终都会被删除，但是也存在严重的缺点：每次都遍历内存中所有的数据，非常消耗 CPU 资源，并且当 key 已过期，但是定时器还处于未唤起状态，这段时间内 key 仍然可以用。 
  + (2)惰性删除策略：在获取 key 时，先判断 key 是否过期，如果过期则删除。这种方式存在一个缺点：如果这个 key 一直未被使用，那么它一直在内存中，其实它已经过期了，会浪费大量的空间。 这两种策略天然的互补，结合起来之后，定时删除策略就发生了一些改变，不在是每次扫描全部的 key 了，而是随机抽取一部分 key 进行检查，这样就降低了对 CPU 资源的损耗，惰性删除策略互补了为检查到的key，基本上满足了所有要求。 但是有时候就是那么的巧，既没有被定时器抽取到，又没有被使用，这些数据又如何从内存中消失？没关系，
  + 还有内存淘汰机制，当内存不够用时，内存淘汰机制就会上场。淘汰策略分为： (1)当内存不足以容纳新写入数据时，新写入操作会报错。（Redis 默认策略） (2)当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的 Key。（LRU推荐使用） (3)当内存不足以容纳新写入数据时，在键空间中，随机移除某个 Key。 (4)当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除最近最少使用的 Key。这种情况一般是把 Redis 既当缓存，又做持久化存储的时候才用。 (5)当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某个 Key。 (6)当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，有更早过期时间的 Key 优先移除。

### Redis的LRU过期策略的具体实现

+ Redis的LRU具体实现： 用栈的形式会导致执行select *的时候大量非热点数据占领头部数据，所以需要改进。 Redis每次按key获取一个值的时候，都会更新value中的lru字段为当前秒级别的时间戳。Redis初始的实现算法很简单，随机从dict中取出五个key,淘汰一个lru字段值最小的。 在3.0的时候，又改进了一版算法，首先第一次随机选取的key都会放入一个pool中(pool的大小为16),pool中的key是按lru大小顺序排列的。接下来每次随机选取的keylru值必须小于pool中最小的lru才会继续放入，直到将pool放满。放满之后，每次如果有新的key需要放入，需要将pool中lru最大的一个key取出。淘汰的时候，直接从pool中选取一个lru最小的值然后将其淘汰。
+ 推荐阅读:[Redis中的LRU淘汰策略分析](https://www.cnblogs.com/linxiyue/p/10945216.html)

### 如何解决Redis缓存雪崩，缓存穿透问题

+ 缓存雪崩:
  + (1)使用 Redis 高可用架构：使用 Redis 集群来保证 Redis 服务不会挂掉
  + (2)缓存时间不一致，给缓存的失效时间，加上一个随机值，避免集体失效
  + (3)限流降级策略：有一定的备案，比如个性推荐服务不可用了，换成热点数据推荐服务
+ 缓存穿透
  + (1)在接口做校验
  +  (2)存null值（缓存击穿加锁）
  +  (3)布隆过滤器拦截： 将所有可能的查询key 先映射到布隆过滤器中，查询时先判断key是否存在布隆过滤器中，存在才继续向下执行，如果不存在，则直接返回。 布隆过滤器将值进行多次哈希bit存储，布隆过滤器说某个元素在，可能会被误判。布隆过滤器说某个元素不在，那么一定不在。
+ 推荐阅读:[缓存穿透，缓存击穿，缓存雪崩解决方案分析](https://blog.csdn.net/zeb_perfect/article/details/54135506)

### Redis的持久化机制（必考）

+ redis为了保证效率，数据缓存在了内存中，但是会周期性的把更新的数据写入磁盘或者把修改操作写入追加的记录文件中，以保证数据的持久化。

  Redis的持久化策略有两种：

  +  (1)RDB：快照形式是直接把内存中的数据保存到一个dump的文件中，定时保存，保存策略。 当Redis需要做持久化时，Redis会fork一个子进程，子进程将数据写到磁盘上一个临时RDB文件中。当子进程完成写临时文件后，将原来的RDB替换掉。
  +  (2)AOF：把所有的对Redis的服务器进行修改的命令都存到一个文件里，命令的集合。 使用AOF做持久化，每一个写命令都通过write函数追加到appendonly.aof中。aof的默认策略是每秒钟fsync一次，在这种配置下，就算发生故障停机，也最多丢失一秒钟的数据。 缺点是对于相同的数据集来说，AOF的文件体积通常要大于RDB文件的体积。根据所使用的fsync策略，AOF的速度可能会慢于RDB。 Redis默认是快照RDB的持久化方式。

+ 推荐阅读:[一文看懂Redis的持久化原理](https://juejin.im/post/5b70dfcf518825610f1f5c16)


### redis主从复制，主从同步

+ (1)从节点执行slaveofmasterIP，保存主节点信息

  (2)从节点中的定时任务发现主节点信息，建立和主节点的socket连接

  (3)从节点发送Ping信号，主节点返回Pong，两边能互相通信 

  (4)连接建立后，主节点将所有数据发送给从节点（数据同步）

  (5)主节点把当前的数据同步给从节点后，便完成了复制的建立过程。接下来，主节点就会持续的把写命令发送给从节点，保证主从数据一致性。

  主从刚刚连接的时候，进行全量同步（RDB）；全同步结束后，进行增量同步(AOF)。

+ 推荐阅读:[深入学习Redis（3）：主从复制](https://www.cnblogs.com/kismetv/p/9236731.html)


### Redis和memcached的区别

+ (1)存储方式上：memcache会把数据全部存在内存之中，断电后会挂掉，数据不能超过内存大小。redis有部分数据存在硬盘上，这样能保证数据的持久性。

  (2)数据支持类型上：memcache对数据类型的支持简单，只支持简单的key-value，而redis支持五种数据类型。

  (3)用底层模型不同：它们之间底层实现方式以及与客户端之间通信的应用协议不一样。redis直接自己构建了VM机制，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求。 

  (4)value的大小：redis可以达到1GB，而memcache只有1MB。

### redis并发竞争key的解决方案

+ (1)分布式锁+时间戳 (2)利用消息队列
+ 推荐阅读:[高并发架构系列：Redis并发竞争key的解决方案详解](https://zhuanlan.zhihu.com/p/52756935)

### Redis与Mysql双写一致性方案

+ 先更新数据库，再删缓存。数据库的读操作的速度远快于写操作的，所以脏数据很难出现。可以对异步延时删除策略，保证读请求完成以后，再进行删除操作。
+ 推荐阅读:[Redis与Mysql双写一致性方案解析](https://zhuanlan.zhihu.com/p/59167071)

### Redis的管道pipeline

+ 对于单线程阻塞式的Redis，Pipeline可以满足批量的操作，把多个命令连续的发送给Redis Server，然后一一解析响应结果。Pipelining可以提高批量处理性能，提升的原因主要是TCP连接中减少了“交互往返”的时间。 pipeline 底层是通过把所有的操作封装成流，redis有定义自己的出入输出流。在 sync() 方法执行操作，每次请求放在队列里面，解析响应包。

## Mysql

### 事务的基本要素(事务特性)

+ (1)原子性：事务是一个原子操作单元，其对数据的修改，要么全都执行，要么全都不执行

  (2)一致性：事务开始前和结束后，数据库的完整性约束没有被破坏。

  (3)隔离性：同一时间，只允许一个事务请求同一数据，不同的事务之间彼此没有任何干扰。

  (4)持久性：事务完成后，事务对数据库的所有更新将被保存到数据库，不能回滚。

### 事务隔离级别、如何解决事务的并发问题(脏读，幻读)（必考）

+ [MySQL 四种事务隔离级的说明](https://www.cnblogs.com/zhoujinyi/p/3437475.html)
+ [数据库事务隔离级别-- 脏读、幻读、不可重复读](https://blog.csdn.net/JIESA/article/details/51317164)

### MVCC,binlog,redolog,undolog都是什么，起什么作用（必考）

+ undolog 也就是我们常说的回滚日志文件 主要用于事务中执行失败，进行回滚，以及MVCC中对于数据历史版本的查看。由引擎层的InnoDB引擎实现,是逻辑日志,记录数据修改被修改前的值,比如"把id='B' 修改为id = 'B2' ，那么undo日志就会用来存放id ='B'的记录”。当一条数据需要更新前,会先把修改前的记录存储在undolog中,如果这个修改出现异常,则会使用undo日志来实现回滚操作,保证事务的一致性。当事务提交之后，undo log并不能立马被删除,而是会被放到待清理链表中,待判断没有事物用到该版本的信息时才可以清理相应undolog。它保存了事务发生之前的数据的一个版本，用于回滚，同时可以提供多版本并发控制下的读（MVCC），也即非锁定读。
+ redoLog 是重做日志文件是记录数据修改之后的值，用于持久化到磁盘中。redo log包括两部分：一是内存中的日志缓冲(redo log buffer)，该部分日志是易失性的；二是磁盘上的重做日志文件(redo log file)，该部分日志是持久的。由引擎层的InnoDB引擎实现,是物理日志,记录的是物理数据页修改的信息,比如“某个数据页上内容发生了哪些改动”。当一条数据需要更新时,InnoDB会先将数据更新，然后记录redoLog 在内存中，然后找个时间将redoLog的操作执行到磁盘上的文件上。不管是否提交成功我都记录，你要是回滚了，那我连回滚的修改也记录。它确保了事务的持久性。
+ MVCC多版本并发控制是MySQL中基于乐观锁理论实现隔离级别的方式，用于读已提交和可重复读取隔离级别的实现。在MySQL中，会在表中每一条数据后面添加两个字段：最近修改该行数据的事务ID，指向该行（undolog表中）回滚段的指针。Read View判断行的可见性，创建一个新事务时，copy一份当前系统中的活跃事务列表。意思是，当前不应该被本事务看到的其他事务id列表。
+ binlog由Mysql的Server层实现,是逻辑日志,记录的是sql语句的原始逻辑，比如"把id='B' 修改为id = ‘B2’。binlog会写入指定大小的物理文件中,是追加写入的,当前文件写满则会创建新的文件写入。 产生:事务提交的时候,一次性将事务中的sql语句,按照一定的格式记录到binlog中。用于复制和恢复在主从复制中，从库利用主库上的binlog进行重播(执行日志中记录的修改逻辑),实现主从同步。业务数据不一致或者错了，用binlog恢复。
+ 推荐阅读[MySQL（5）| 五分钟搞清楚 MVCC 机制](https://juejin.im/post/5c68a4056fb9a049e063e0ab#heading-0)

### binlog和redolog的区别

+ 区别：
  + redolog是在InnoDB存储引擎层产生，而binlog是MySQL数据库的上层服务层产生的。
  + 两种日志记录的内容形式不同。MySQL的binlog是逻辑日志，其记录是对应的SQL语句。而innodb存储引擎层面的重做日志是物理日志。
  + 两种日志与记录写入磁盘的时间点不同，binlog日志只在事务提交完成后进行一次写入。而innodb存储引擎的重做日志在事务进行中不断地被写入，并日志不是随事务提交的顺序进行写入的。
  + binlog不是循环使用，在写满或者重启之后，会生成新的binlog文件，redolog是循环使用。
  + binlog可以作为恢复数据使用，主从复制搭建，redolog作为异常宕机或者介质故障后的数据恢复使用。
+ 推荐阅读：[一文带你看懂binlog和redo log](https://www.jianshu.com/p/907f9002442e)

### Mysql如何保证一致性和持久性

+ MySQL为了保证ACID中的一致性和持久性，使用了WAL(Write-Ahead Logging,先写日志再写磁盘)。Redo log就是一种WAL的应用。当数据库忽然掉电，再重新启动时，MySQL可以通过Redo log还原数据。也就是说，每次事务提交时，不用同步刷新磁盘数据文件，只需要同步刷新Redo log就足够了。

### InnoDB的行锁

+ 共享锁(S)：用法lock in share mode，又称读锁，允许一个事务去读一行，阻止其他事务获得相同数据集的排他锁。若事务T对数据对象A加上S锁，则事务T可以读A但不能修改A，其他事务只能再对A加S锁，而不能加X锁，直到T释放A上的S锁。这保证了其他事务可以读A，但在T释放A上的S锁之前不能对A做任何修改。
+ 排他锁(X)：用法for update，又称写锁，允许获取排他锁的事务更新数据，阻止其他事务取得相同的数据集共享读锁和排他写锁。若事务T对数据对象A加上X锁，事务T可以读A也可以修改A，其他事务不能再对A加任何锁，直到T释放A上的锁。在没有索引的情况下，InnoDB只能使用表锁。
+ 推荐阅读：[mysql锁——innodb的行级锁](https://www.cnblogs.com/huangfuyuan/p/9510022.html)

### myisam和innodb的区别，什么时候选择myisam

+ https://blog.csdn.net/u010598360/article/details/81482225

### 为什么选择B+树作为索引结构（必考）

- Hash索引：Hash索引底层是哈希表，哈希表是一种以key-value存储数据的结构，所以多个数据在存储关系上是完全没有任何顺序关系的，所以，对于区间查询是无法直接通过索引查询的，就需要全表扫描。所以，**哈希索引只适用于等值查询的场景**。而B+ 树是一种多路平衡查询树，所以他的节点是天然有序的（左子节点小于父节点、父节点小于右子节点），所以对于范围查询的时候不需要做全表扫描
- 二叉查找树：**解决了排序的基本问题，但是由于无法保证平衡，可能退化为链表。**
- 平衡二叉树：**通过旋转解决了平衡的问题，但是旋转操作效率太低。**
- 红黑树：通过舍弃严格的平衡和引入红黑节点，解决了 AVL旋转效率过低的问题，但是在磁盘等场景下，树仍然太高，IO次数太多。
- B+树：在B树的基础上，将非叶节点改造为不存储数据纯索引节点，进一步降低了树的高度；此外将叶节点使用指针连接成链表，范围查询更加高效。
- 推荐阅读：[一步步分析为什么B+树适合作为索引的结构 以及索引原理 (阿里面试)](https://www.cnblogs.com/aspirant/p/9214485.html)

### 索引B+树的叶子节点都可以存哪些东西（必考）

+ 可能存储的是整行数据，也有可能是主键的值。B+树的叶子节点存储了整行数据的是主键索引，也被称之为**聚簇索引**。而索引B+ Tree的叶子节点存储了主键的值的是**非主键索引**，也被称之为非聚簇索引
+ 推荐阅读：[什么是覆盖索引?如何利用覆盖索引进行SQL语句优化？](https://blog.csdn.net/qq_15037231/article/details/87891683)

### 查询在什么时候不走（预期中的）索引（必考）

1. 模糊查询 %like
2. 索引列参与计算,使用了函数
3. 非最左前缀顺序
4. where对null判断
5. where不等于
6. or操作有至少一个字段没有索引
7. 需要回表的查询结果集过大（超过配置的范围）

+ 推荐阅读:

  [MySQL高级 之 索引失效与优化详解](https://blog.csdn.net/wuseyukui/article/details/72312574)

  [sql优化的几种方式](https://blog.csdn.net/qq_38789941/article/details/83744271)

### sql如何优化

1. 创建并使用正确的索引
2. 只返回需要的字段
3. 减少交互次数（批量提交）
4. 设置合理的Fetch Size（数据每次返回给客户端的条数）

### explain是如何解析sql的

+ 推荐阅读:[MySQL 性能优化神器 Explain 使用分析](https://segmentfault.com/a/1190000008131735)

### order by原理

+ [order by的工作原理](https://www.jianshu.com/p/0d2ba78e6474)



## **JVM**

### 运行时数据区域（内存模型）（必考）

1. 程序计数器：程序计数器是一块较小的内存空间，它可以看作是当前线程所执行的字节码的行号指示器。在虚拟机的概念模型里，字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖这个计数器来完成。**是线程私有**”的内存。
2. Java虚拟机栈：与程序计数器一样，Java虚拟机栈（Java Virtual Machine Stacks）也是线程私有的，它的生命周期与线程相同。虚拟机栈描述的是Java方法执行的内存模型：**每个方法在执行的同时都会创建一个栈帧 ，用于存储局部变量表、操作数栈、动态链接、方法出口等信息**。每一个方法从调用直至执行完成的过程，就对应着一个栈帧在虚拟机栈中入栈到出栈的过程。
3. 本地方法栈：本地方法栈（Native Method Stack）与虚拟机栈所发挥的作用是非常相似的，它们之间的区别不过是虚拟机栈为虚拟机执行Java方法（也就是字节码）服务，而本地方法栈则为虚拟机使用到的Native方法服务。
4. Java堆：对于大多数应用来说，Java堆是Java虚拟机所管理的内存中最大的一块。Java堆是被所有线程共享的一块内存区域，在虚拟机启动时创建。此内存区域的唯一目的就是**存放对象实例**，几乎所有的对象实例都在这里分配内存。

### 分代回收

+ HotSpot JVM把年轻代分为了三部分：1个Eden区和2个Survivor区（分别叫from和to）。一般情况下，新创建的对象都会被分配到Eden区(一些大对象特殊处理),这些对象经过第一次Minor GC后，如果仍然存活，将会被移到Survivor区。对象在Survivor区中每熬过一次Minor GC，年龄就会增加1岁，当它的年龄增加到一定程度时，就会被移动到年老代中。

+ 因为年轻代中的对象基本都是朝生夕死的，所以在年轻代的垃圾回收算法使用的是复制算法，复制算法的基本思想就是将内存分为两块，每次只用其中一块，当这一块内存用完，就将还活着的对象复制到另外一块上面。复制算法不会产生内存碎片。

+ **在GC开始的时候，对象只会存在于Eden区和名为“From”的Survivor区**，Survivor区“To”是空的。紧接着进行GC，Eden区中所有存活的对象都会被复制到“To”，而在“From”区中，仍存活的对象会根据他们的年龄值来决定去向。年龄达到一定值(年龄阈值，可以通过-XX:MaxTenuringThreshold来设置)的对象会被移动到年老代中，没有达到阈值的对象会被复制到“To”区域。经过这次GC后，Eden区和From区已经被清空。这个时候，“From”和“To”会交换他们的角色，也就是新的“To”就是上次GC前的“From”，新的“From”就是上次GC前的“To”。不管怎样，都会保证名为To的Survivor区域是空的。Minor GC会一直重复这样的过程，直到“To”区被填满，“To”区被填满之后，会将所有对象移动到年老代中。



### 垃圾回收机制（必考）

+ **引用计数法**：引用计数法是一种简单但速度很慢的垃圾回收技术。每个对象都含有一个引用计数器,当有引用连接至对象时,引用计数加1。当引用离开作用域或被置为null时,引用计数减1。虽然管理引用计数的开销不大,但这项开销在整个程序生命周期中将持续发生。垃圾回收器会在含有全部对象的列表上遍历,当发现某个对象引用计数为0时,就释放其占用的空间。
+ **可达性分析算法**：这个算法的基本思路就是通过一系列的称为“GC Roots”的对象作为起始点，从这些节点开始向下搜索，搜索所走过的路径称为引用链，当一个对象到GC Roots没有任何引用链相连（用图论的话来说，就是从GC Roots到这个对象不可达）时，则证明此对象是不可用的。



### 哪些对象可以作为GC Roots

+ 虚拟机栈（栈帧中的本地变量表）中引用的对象。
+ 方法区中类静态属性引用的对象。
+ 方法区中常量引用的对象。
+ 本地方法栈中JNI（即一般说的Native方法）引用的对象。



### 垃圾回收算法（必考）

+ **复制**：先暂停程序的运行,然后将所有存活的对象从当前堆复制到另一个堆,没有被复制的对象全部都是垃圾。当对象被复制到新堆时,它们是一个挨着一个的,所以新堆保持紧凑排列,然后就可以按前述方法简单,直接的分配了。缺点是一浪费空间,两个堆之间要来回倒腾,二是当程序进入稳定态时,可能只会产生极少的垃圾,甚至不产生垃圾,尽管如此,复制式回收器仍会将所有内存自一处复制到另一处。
+ **标记-清除**：同样是从堆栈和静态存储区出发,遍历所有的引用,进而找出所有存活的对象。每当它找到一个存活的对象,就会给对象一个标记,这个过程中不会回收任何对象。只有全部标记工作完成的时候,清理动作才会开始。在清理过程中,没有标记的对象会被释放,不会发生任何复制动作。所以剩下的堆空间是不连续的,垃圾回收器如果要希望得到连续空间的话,就得重新整理剩下的对象。
+ **标记-整理**：它的第一个阶段与标记/清除算法是一模一样的，均是遍历GC Roots，然后将存活的对象标记。移动所有存活的对象，且按照内存地址次序依次排列，然后将末端内存地址以后的内存全部回收。因此，第二阶段才称为整理阶段。
+ **分代收集算法**：把Java堆分为新生代和老年代，然后根据各个年代的特点采用最合适的收集算法。新生代中，对象的存活率比较低，所以选用复制算法，老年代中对象存活率高且没有额外空间对它进行分配担保，所以使用“标记-清除”或“标记-整理”算法进行回收。

### Minor GC和Full GC触发条件

- Minor GC触发条件：当Eden区满时，触发Minor GC。
- Full GC触发条件：
  1. 调用System.gc时，系统建议执行Full GC，但是不必然执行
  2. 老年代空间不足
  3. 方法区空间不足
  4. 通过Minor GC后进入老年代的平均大小大于老年代的可用内存
  5. 由Eden区、From Space区向To Space区复制时，对象大小大于To Space可用内存，则把该对象转存到老年代，且老年代的可用内存小于该对象大小

### GC中Stop the world（STW）

+ 在执行垃圾收集算法时，Java应用程序的其他所有除了垃圾收集收集器线程之外的线程都被挂起。**此时，系统只能允许GC线程进行运行，其他线程则会全部暂停，等待GC线程执行完毕后才能再次运行**。这些工作都是由虚拟机在后台自动发起和自动完成的，是在用户不可见的情况下把用户正常工作的线程全部停下来，这对于很多的应用程序，尤其是那些对于实时性要求很高的程序来说是难以接受的。

  但不是说GC必须STW,你也可以选择降低运行速度但是可以并发执行的收集算法，这取决于你的业务。

### 各垃圾回收器的特点及区别

+ **新生代收集器**
  + Serial收集器
  + ParNew 收集器
  + Parallel Scavenge 收集器
+ **老年代收集器**
  + Serial Old收集器
  + Parallel Old收集器
  + CMS收集器
  + G1收集器

+ 推荐阅读：

  [JVM垃圾回收](https://github.com/zlnnjit/cs-inter/blob/master/note/jvm/JVM垃圾回收.md)

  [深入理解JVM(3)——7种垃圾收集器](https://crowhawk.github.io/2017/08/15/jvm_3/)



### G1和CMS的比较

1. CMS收集器是获取最短回收停顿时间为目标的收集器，因为CMS工作时，GC工作线程与用户线程可以并发执行，以此来达到降低手机停顿时间的目的（只有初始标记和重新标记会STW）。但是CMS收集器对CPU资源非常敏感。在并发阶段，虽然不会导致用户线程停顿，但是会占用CPU资源而导致引用程序变慢，总吞吐量下降。
2. CMS仅作用于老年代，是基于标记清除算法，所以清理的过程中会有大量的空间碎片。
3. CMS收集器无法处理浮动垃圾，由于CMS并发清理阶段用户线程还在运行，伴随程序的运行自热会有新的垃圾不断产生，这一部分垃圾出现在标记过程之后，CMS无法在本次收集中处理它们，只好留待下一次GC时将其清理掉。
4. G1是一款面向服务端应用的垃圾收集器，适用于多核处理器、大内存容量的服务端系统。G1能充分利用CPU、多核环境下的硬件优势，使用多个CPU（CPU或者CPU核心）来缩短STW的停顿时间，它满足短时间停顿的同时达到一个高的吞吐量。
5. 从JDK 9开始，G1成为默认的垃圾回收器。当应用有以下任何一种特性时非常适合用G1：Full GC持续时间太长或者太频繁；对象的创建速率和存活率变动很大；应用不希望停顿时间长(长于0.5s甚至1s)。
6. G1将空间划分成很多块（Region），然后他们各自进行回收。堆比较大的时候可以采用，采用复制算法，碎片化问题不严重。整体上看属于标记整理算法,局部(region之间)属于复制算法。
7. G1 需要记忆集 (具体来说是卡表)来记录新生代和老年代之间的引用关系，这种数据结构在 G1 中需要占用大量的内存，可能达到整个堆内存容量的 20% 甚至更多。而且 G1 中维护记忆集的成本较高，带来了更高的执行负载，影响效率。所以 CMS 在小内存应用上的表现要优于 G1，而大内存应用上 G1 更有优势，大小内存的界限是6GB到8GB。



### 双亲委派模型

+ 双亲委派的意思是如果一个类加载器需要加载类，那么首先它会把这个类请求委派给父类加载器去完成，每一层都是如此。一直递归到顶层，当父加载器无法完成这个请求时，子类才会尝试去加载。

+ 推荐阅读:

  [浅谈双亲委派和破坏双亲委派](https://blog.csdn.net/u012129558/article/details/81540804)

  [双亲委派模型与自定义类加载器](https://blog.csdn.net/huachao1001/article/details/52297075)

### JDBC和双亲委派模型关系

+ 因为类加载器受到加载范围的限制，在某些情况下父类加载器无法加载到需要的文件，这时候就需要委托子类加载器去加载class文件。

+ 推荐阅读:

  [阿里面试题：JDBC、Tomcat为什么要破坏双亲委派模型](https://www.javazhiyin.com/44347.html)

  [面试官：说说双亲委派模型？](https://juejin.im/post/5cd02252f265da0393787d46)



## Java并发

### HashMap和ConcurrentHashMap区别（必考）

+ 由于HashMap是线程不同步的，虽然处理数据的效率高，但是在多线程的情况下存在着安全问题，因此设计了CurrentHashMap来解决多线程安全问题。

+ **HashMap在put的时候，插入的元素超过了容量（由负载因子决定）的范围就会触发扩容操作，就是rehash，这个会重新将原数组的内容重新hash到新的扩容数组中，在多线程的环境下，存在同时其他的元素也在进行put操作，如果hash值相同，可能出现同时在同一数组下用链表表示，造成闭环，导致在get时会出现死循环，所以HashMap是线程不安全的。**

  


### ConcurrentHashMap的数据结构（必考）

+ **在JDK1.7版本中，ConcurrentHashMap维护了一个Segment数组，Segment这个类继承了重入锁ReentrantLock，并且该类里面维护了一个 HashEntry<K,V>[] table数组，在写操作put，remove，扩容的时候，会对Segment加锁，所以仅仅影响这个Segment，不同的Segment还是可以并发的，所以解决了线程的安全问题，同时又采用了分段锁也提升了并发的效率。在JDK1.8版本中，ConcurrentHashMap摒弃了Segment的概念，而是直接用Node数组+链表+红黑树的数据结构来实现，并发控制使用Synchronized和CAS来操作，整个看起来就像是优化过且线程安全的HashMap。**

+ 推荐阅读：[HashMap? ConcurrentHashMap? 相信看完这篇没人能难住你！](https://crossoverjie.top/2018/07/23/java-senior/ConcurrentHashMap/#comments)


### 高并发HashMap的环是如何产生的

+ HashMap的环：若当前线程此时获得ertry节点，但是被线程中断无法继续执行，此时线程二进入transfer函数，并把函数顺利执行，此时新表中的某个位置有了节点，之后线程一获得执行权继续执行，因为并发transfer，所以两者都是扩容的同一个链表，当线程一执行到e.next = new table[i] 的时候，由于线程二之前数据迁移的原因导致此时new table[i] 上就有ertry存在，所以线程一执行的时候，会将next节点，设置为自己，导致自己互相使用next引用对方，因此产生链表，导致死循环。

+ 推荐阅读：[老生常谈，HashMap的死循环](https://juejin.im/post/5a66a08d5188253dc3321da0#heading-0)


### volatile作用（必考）

+ volatile在多处理器开发中保证了共享变量的“ 可见性”。可见性的意思是当一个线程修改一个共享变量时，另外一个线程能读到这个修改的值。(共享内存，私有内存)

+ volatile关键字通过`“内存屏障”`来防止指令被重排序。

+ 推荐阅读：[Java并发编程：volatile关键字解析](https://www.cnblogs.com/dolphin0520/p/3920373.html)


### Atomic类如何保证原子性（CAS操作）（必考）

+ CAS是英文单词CompareAndSwap的缩写，中文意思是：比较并替换。CAS需要有3个操作数：内存地址V，旧的预期值A，即将要更新的目标值B。CAS指令执行时，当且仅当内存地址V的值与预期值A相等时，将内存地址V的值修改为B，否则就什么都不做。整个比较并替换的操作是一个原子操作。如 Intel 处理器，比较并交换通过指令的 cmpxchg 系列实现。

### CAS操作ABA问题

+ 如果在这段期间它的值曾经被改成了B，后来又被改回为A，那CAS操作就会误认为它从来没有被改变过。Java并发包为了解决这个问题，提供了一个带有标记的原子引用类“**AtomicStampedReference**”，它可以通过控制变量值的版本来保证CAS的正确性。
+ 推荐阅读：[Java CAS 原理剖析](https://juejin.im/post/5a73cbbff265da4e807783f5)

### synchronized和Lock的区别（必考）

1. 首先synchronized是java内置关键字在jvm层面，Lock是个java类。
2. synchronized无法判断是否获取锁的状态，Lock可以判断是否获取到锁，并且可以主动尝试去获取锁。
3. synchronized会自动释放锁(a 线程执行完同步代码会释放锁 ；b 线程执行过程中发生异常会释放锁)，Lock需在finally中手工释放锁（unlock()方法释放锁），否则容易造成线程死锁。
4. 用synchronized关键字的两个线程1和线程2，如果当前线程1获得锁，线程2线程等待。如果线程1阻塞，线程2则会一直等待下去，而Lock锁就不一定会等待下去，如果尝试获取不到锁，线程可以不用一直等待就结束了。
5. synchronized的锁可重入、不可中断、非公平，而Lock锁可重入、可判断、可公平（两者皆可）
6. Lock锁适合大量同步的代码的同步问题，synchronized锁适合代码少量的同步问题。

+ 推荐阅读：[谈谈-synchronized和reentrantlock-的区别]([https://github.com/zlnnjit/cs-inter/blob/master/note/juc/Java%E5%B9%B6%E5%8F%91%E8%BF%9B%E9%98%B6%E6%80%BB%E7%BB%93.md#%E8%B0%88%E8%B0%88-synchronized%E5%92%8Creentrantlock-%E7%9A%84%E5%8C%BA%E5%88%AB](https://github.com/zlnnjit/cs-inter/blob/master/note/juc/Java并发进阶总结.md#谈谈-synchronized和reentrantlock-的区别))

### 为什么要使用线程池（必考）

- **降低资源消耗**。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。
- **提高响应速度**。当任务到达时，任务可以不需要的等到线程创建就能立即执行。
- **提高线程的可管理性**。线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。

### 核心线程池ThreadPoolExecutor的参数（必考）

+ **corePoolSize**：指定了线程池中的线程数量
+ **maximumPoolSize**：指定了线程池中的最大线程数量
+ **keepAliveTime**：线程池维护线程所允许的空闲时间
+ **unit**: keepAliveTime 的单位。
+ **workQueue**：任务队列，被提交但尚未被执行的任务。
+ **threadFactory**：线程工厂，用于创建线程，一般用默认的即可。
+ **handler**：拒绝策略。当任务太多来不及处理，如何拒绝任务。
+ 推荐阅读：[threadpoolexecutor构造函数重要参数分析]([https://github.com/zlnnjit/cs-inter/blob/master/note/juc/Java%E5%B9%B6%E5%8F%91%E8%BF%9B%E9%98%B6%E6%80%BB%E7%BB%93.md#threadpoolexecutor%E6%9E%84%E9%80%A0%E5%87%BD%E6%95%B0%E9%87%8D%E8%A6%81%E5%8F%82%E6%95%B0%E5%88%86%E6%9E%90](https://github.com/zlnnjit/cs-inter/blob/master/note/juc/Java并发进阶总结.md#threadpoolexecutor构造函数重要参数分析))

### ThreadPoolExecutor的工作流程（必考）

线程池的线程执行规则跟任务队列有很大的关系。

+ 下面都假设任务队列没有大小限制：
  + 如果线程数量<=核心线程数量，那么直接启动一个核心线程来执行任务，不会放入队列中。
  + 如果线程数量>核心线程数，但<=最大线程数，并且任务队列是LinkedBlockingDeque的时候，超过核心线程数量的任务会放在任务队列中排队。
  + 如果线程数量>核心线程数，但<=最大线程数，并且任务队列是SynchronousQueue的时候，线程池会创建新线程执行任务，这些任务也不会被放在任务队列中。这些线程属于非核心线程，在任务完成后，闲置时间达到了超时时间就会被清除。
  + 如果线程数量>核心线程数，并且>最大线程数，当任务队列是LinkedBlockingDeque，会将超过核心线程的任务放在任务队列中排队。也就是当任务队列是LinkedBlockingDeque并且没有大小限制时，**线程池的最大线程数设置是无效的**，他的线程数最多不会超过核心线程数。
  + 如果线程数量>核心线程数，并且>最大线程数，当任务队列是SynchronousQueue的时候，会因为线程池拒绝添加任务而抛出异常。
+ 任务队列大小有限时
  + 当LinkedBlockingDeque塞满时，新增的任务会直接创建新线程来执行，当创建的线程数量超过最大线程数量时会抛异常。
  + SynchronousQueue没有数量限制。因为他根本不保持这些任务，而是直接交给线程池去执行。当任务数量超过最大线程数时会直接抛异常。
+ 推荐阅读:[Java多线程-线程池ThreadPoolExecutor构造方法和规则](https://blog.csdn.net/qq_25806863/article/details/71126867)



+ 10. 如何控制线程池线程的优先级
+ 11. 线程之间如何通信
+ 12. Boolean占几个字节
+ 13. jdk1.8/jdk1.7都分别新增了哪些特性
+ 14. Exception和Error

**Spring**

+ 1. Spring的IOC/AOP的实现（必考）
+ 2. 动态代理的实现方式（必考）
+ 3. Spring的后置处理器
+ 4. Spring的@Transactional如何实现的（必考）
+ 5. Spring的事务传播级别

**其他**

+ 1. 高并发系统的限流如何实现
+ 2. 高并发秒杀系统的设计
+ 3. 负载均衡如何设计

**补充**

另外还会考一些计算机网络，操作系统啊之类的。像消息队列，RPC框架这种考的比较少。计算机网络就是分层啊，tcp/udp啊，三次握手之类的。操作系统就是进程与线程啊，进程的数据结构以及如何通信之类的。数据结构的排序算法也比较常考，考的话一定会让你手写个快排。剩下的算法题就靠LeetCode的积累了。其实非算法岗考的算法题都蛮简单的，很多题完全就是考察你智力是否正常，稍微难点的涉及到一些算法思想的按照LeetCode题目类型的分类，每种题做一两道基本就能完全应付面试了。


**面试感受及评价**

除了外企，体验最好的就是阿里。绝对的脱颖而出，无论是面试官的专业程度还是面试官对参与面试人员的态度都完全突出于其他公司。非常的尊重人，以及会引导我去作出正确的回答，唯一就是阿里的HR是非常强势的，永远有一票否决权。而有些公司面试官会故意误导你，想方设法让你说出错误的答案，并且有些态度极其傲慢，让人感觉很不尊重人。这里点名批评面试体验最差的两家公司：美团和Boss直聘。

外企的话，体验都很好，但是我都还没面试完，后面会更新的。微软是英文面的，亚马逊不是。这俩都是以算法为主，微软除了算法还聊了操作系统和计算机网络，亚马逊聊了较长时间的项目细节。


**最后**

最后说下自己的情况，17年在京东实习，19年7月离职。正式工作时间很短，就一年（算实习两年），而且19年有半年的时间准备考研所以有半年的空档期，这也是为什么我被很多HR挂了的原因。虽然Offer没拿几个，但是一半多都面到HR面了，所以对于两三年经验的感觉整理的问题还是比较有代表性的。