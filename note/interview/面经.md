# 快手

## 1.快手高级开发社招

### 一面

+ Spring 原理、Spring IOC、AOP

  + 这个问题 最好可以多说一点，比如 对于IOC，不妨把Bean 如何加载、如何初始化以及如何注册到IOC容器中的详细过程说一下， 涉及BeanDefinition、BeanFactory也深入细节聊一下。

+ 一个请求过来在Spring中发生了哪些事情

  + 这个问题不妨把一个请求过来在TCP层面上建立连接、操作系统如何处理连接、Web容器接收到连接对象后做了哪些事情、Spring 如何对接收到的请求进行处理都说一下，当然最终还是落在Spring 容器内部如何处理一个请求，这个过程一定要说清楚，需要体现细节。在说前面的内容的时候，可以放心面试官不会打断你。

+ 手写一个栈，实现 push，pop方法，以及 max(获取最大的元素) 方法，要求时间复杂度为 O(1)

  + 这是一个考察数据结构的问题，一方面需要候选⼈对数据结构有所了解，一方面也需要候选人对代码有驾驭能力(毕竟要手写代码)。面试官会给一定的时间，在这段时间里，面试官不会打扰你，并尽可能为你提供方便，比如，签字笔不好用，面试官会帮你更换。据我个人经验，凡是面对需要写代码的问题，都不要急着放弃，静下心来，仔细思考，都是可以写得不错的。如果没能写出来，面试官会问你实现思路，如果你的思路很优化，一样可以过了这道题，但是前提是：你的代码不能一行都不写。

    对于数据结构的考察的话，我建议看一下jdk中对于List、Stack、Tree、Set的实现，比如，至少你要知道，如果让你实现一个单链表，你会如何实现；比如，你可能会定义一个Node节点，里面有当前节点的key和value，还有对于下一个节点的引用。如果熟悉jdk对于各种数据结构的实现，这道题是很容易过的。

+ JVM内存结构

  + 这个问题需要你能画出JVM内存结构的图，画出方法区、堆、程序计算器、虚拟机栈、本地方法栈，并说出每一个部分具体是什么作用，比如，哪些是线程共享的，哪些是线程独享的，哪些地方存放了什么数据，为什么会这样存放，哪些虚拟机参数对这些空间大小是有影响的，可以如何配置。这些都比较常规

+ 手写一个单例

  + 这个基本上大多数公司都会考察的。要写一个基于懒汉式的双重检测的单例。单例有三个比较关键的点，一是私有构造方法，避免外部new出对象；二是保证唯一性；三是提供一个全局访问点。

    另外，懒汉式双重检测的实现方式 有三点需要注意的地方，一是 全局访问点必须是静态的，外界使用可以通过类直接调用，二是在进入锁之后还需要校验，三是保存单例对象的私有变量一定要用volatile修饰，这个地方可以多说一些，比如volatile防止指令重排序，保证内存可见性(JVM层面和CPU层面可以分别说)。volatile 这个地方能说的东西还是很多的，基本上可以与面试官再聊二十分钟了。

+ HashMap相关

  + 对于 HashMap 其实一般高级岗位及以上不再会问这个东西了，一旦问了，肯定不是让你只说一下数组+链表的。对于它的实现，不同版本实现方式不一样。

    在jdk1.8之后，HashMap除了数组+链表之外，引用了红黑树。那么好了，你需要说明 对于 引用了红黑树的 HashMap 如何put一个元素，以及链表是在何时转化为红黑树的。比如，首先需要知道这个元素落在哪一个数组里，获取hashcode后并不是对数组长度取余来确定的，而是高低位异或求与来得到的。这个地方首先得知道异或求与是做什么样的运算的。

    之后说一下在HashMap中的实现，比如hashcode无符号右移16位后和原hashcode做异或运算，这相当于把hashcode的高16位拿过来和hashcode的低16位做异或运算，因为无符号右移后前面说的16位都补零，这就是前面说的 "高低位异或“，进而是“求与”，和谁求与呢，和数组长度减1 求与。说到这里起码能够证明你是看过源码的，接下来说说你的思考，比如我们知道对于hashmap 初始化容量决定了数组大小，一般我们对于数组这个初始容量的设置是有规律的，它应该是 2^n 。这个初始容量的设置影响了HashMap的效率，那又涉及到影响HashMap效率的主要因素，比如初始容量和负载因子。

    当已用数组达到容量与负载因子的乘积之后会进行一个rehash的过程，这个地方涉及到的如何rehash及各种算法如果有时间也是可以说的，没有时间不说也没有关系。回到刚才说的 2^n, 可以说说它为什么是2^n。

    当我们说什么东西为什么是这样的时候，我们一般从两个⻆度考虑，一个是：这样做有什么好处，另一个是：不这样做有什么坏处。我们刚才说到“求与”这个过程，如果不是 2^n, 会导致较多的哈希碰撞(具体原因可以自己分析一下或者百度一下)，这个会影响HashMap的效率。说完上面这些，既表明你看过源码，又表明你有自己的思考了，当然也可以进一步说说它是在什么条件下以及如何进行扩容的（如果时间允许，并且面试官也有耐心继续听下去）。

    对于put操作，这才只是第一步，找到数组的位置，接下来 要看这个位置也没有元素，如果没有，直接放进去就可以，如果有，要看怎么放进去，jdk1.8中 对于HashMap的实现中，是基于Node(链表节点) 和TreeNode(红黑树节点) 的，当然它们继承了Entry。

    那么，如果数组当前位置已经有了元素，就得知道这个元素是链表的节点还是红黑树的节点，以便进一步确认接下来要put的元素是以链表的方式插入，还是以红黑树的方式插入，这个地方在源码中进入了一个类型的判断，如果是链表的节点，就以链表的方式把要put的节点插入到next为null的节点上，如果是红黑树的节点，就要以红黑树的方式插入一个节点。

    接下来其实不是考察的重点，但是也可以说说，就是:

    (1) 为什么要引入红黑树，

    (2)如何在红黑树中插入一个节点。对于这两个问题，首先，引入红黑树的好处是为了
    提高查询效率，要说出O(log2(n))，但是在提高查找效率的同时 也在插入的时候更加耗时，那可以说一下为什么更加耗时，自然带出第二个问题，如何在红黑树中插入一个节点，比如 当插入一个节点的时候我们会默认它是红色的(这个地方可以结合红黑树特点说一下 我们为什么默认它是红色的，从黑色高度以及相邻两节点不同为红色入手)，插入后如果父节点是黑色的 就不需要动了，但假如是红色的，就需要进行左旋和右旋操作，如果很了解，可以细说左旋右旋如何实现，如果不是很了解，到此为止也ok。

    说到这里，我们忽略了一个重要的点，就是链表转换为红黑树的条件，说出链表长度到8(相当于红黑树开始第四层) 以及 数组大小达到64就已经够了，也可以进一步说一下 链表是如何转换为红黑树的。说完也可以说一下 ConcurrentHashMap中也是一样的，然后接下来就引入对ConcurrentHashMap的理解，⽐如 在什么地⽅会涉及到线程安全问题 以及ConcurrentHashMap是如何解决的，说说CAS，说完CAS再说说AQS，自由发挥吧。

+ JVM四种引入类型

  + 这个问题比较简单，强引入、弱引入、软引入、虚引入，说一下它们各自的特点和GC对它们的不同处理方式，再说一下常用的应用场景或者jdk的实现中对它们的使用，比如，ThreadLocal 的静态内部类ThreadLocalMap，它的Key是弱引用的，也可以说一下 在你的理解中 为什么它是弱引用的，假如不是会怎么样。

+ SpringBoot 启动过程

  + 这个主要是从它基于Spring的事件发布和监听机制开始说起 就没什么问题。

### 二面

+ 类加载过程

  + 加载 链接 初始化，链接又分为验证准备和解析，每一个阶段是做了什么要说清楚。Object a = new Object()；这行代码做了哪些事情，需要从类加载开始说起，这个相当于上一问题的延续，所以一定要清楚每一个环节做了哪些事情的，否则这个问题不可能说清楚。

    说完类加载的过程，再说一下开辟内存空间、初始化内存空间以及把内存地址赋值给变量a，接下来可以进一步说一下JVM或者CPU层面对指令的优化，以及在某些时刻我们需要避免它做这样的优化，比如在单例中我们的实例需要用volatile修饰避免指令重排序(可以说一下在new一个对象的过程中如果指令重排序了会导致什么结果)。

+ maven的熟练程度

  + 有哪些类型

+ Linux命令⾏的熟练程度

  +  ${} 和 $() 区别

+ 消息队列的熟练程度

  + Kafka分区，如何分区 等等(因为我过往项⽬经验中写了kafka，所以才会被问及，如果写了其他消息队列，也可能会被问及)

+ Netty

  + 从NIO开始说 肯定是没错的，再说说Netty的实现⽅式，以及它除了IO之外还⼲了哪些事情。

### 三面

+ 根据过往项目经验依次介绍业务
  + 这就需要在面试之前把自己的做过的项目好好总结一下，它们主要做的业务是什么，解决了什么问题，架构是什么样的，以及你在其中做了哪些⼯作。这个地方一定要准备充分，少要能扛得住面试官三连问。否则会被认 你不太清楚你们之前做的到底是什么，那你在业务能力方便可能是不太match的。
+ 你有什么问题想问面试官的
  + 这个地方因人而异，但无论怎样，都不要什么都不问，至少你要表现一点对于岗位的兴趣吧。如问一下公司业务，团队构成，技术栈，以及你所应聘的这个岗位大概做哪些工作。

### 四面

+ HR面试。这一轮可以说是斗智斗勇的一个环节，会考察到些软技能、个人成长、职业素质，也会问一下期望薪资。





# 其他

## 1.京东18届一年半经验校招

**ZooKeeper**

+ CAP定理
  + 一个分布式系统不可能同时满足以下三种,一致性（C:Consistency）,可用性（A:Available）,分区容错性（P:Partition Tolerance）. 在此ZooKeeper保证的是CP，ZooKeeper不能保证每次服务请求的可用性，在极端环境下，ZooKeeper可能会丢弃一些请求，消费者程序需要重新请求才能获得结果。 另外在进行leader选举时集群都是不可用，所以说，ZooKeeper不能保证服务可用性。（Base理论CA强一致性和最终一致性）
  + 推荐阅读
    + [谈谈分布式系统的CAP理论](https://zhuanlan.zhihu.com/p/33999708)
    + [CAP理论中的P到底是个什么意思？](https://www.zhihu.com/question/54105974)
    + [分布式理论(二) - BASE理论](https://juejin.im/post/5b2663fcf265da59a401e6f8)
+ ZAB协议
  + ZAB协议包括两种基本的模式：崩溃恢复和消息广播。当整个 Zookeeper 集群刚刚启动或者Leader服务器宕机、重启或者网络故障导致不存在过半的服务器与 Leader 服务器保持正常通信时，所有服务器进入崩溃恢复模式，首先选举产生新的 Leader 服务器，然后集群中 Follower 服务器开始与新的 Leader 服务器进行数据同步。 当集群中超过半数机器与该 Leader 服务器完成数据同步之后，退出恢复模式进入消息广播模式，Leader 服务器开始接收客户端的事务请求生成事物提案来进行事务请求处理。
  + 推荐阅读
    + [看大牛如何分析Zookeeper ZAB 协议](https://juejin.im/post/5b924b0de51d450e9a2de615)
+ Leader选举算法和流程
  + FastLeaderElection(默认提供的选举算法): 目前有5台服务器，每台服务器均没有数据，它们的编号分别是1,2,3,4,5,按编号依次启动，它们的选择举过程如下： (1)服务器1启动，给自己投票，然后发投票信息，由于其它机器还没有启动所以它收不到反馈信息，服务器1的状态一直属于Looking。 (2)服务器2启动，给自己投票，同时与之前启动的服务器1交换结果，由于服务器2的编号大所以服务器2胜出，但此时投票数没有大于半数，所以两个服务器的状态依然是LOOKING。 (3)服务器3启动，给自己投票，同时与之前启动的服务器1,2交换信息，由于服务器3的编号最大所以服务器3胜出，此时投票数正好大于半数，所以服务器3成为leader，服务器1,2成为follower。 (4)服务器4启动，给自己投票，同时与之前启动的服务器1,2,3交换信息，尽管服务器4的编号大，但之前服务器3已经胜出，所以服务器4只能成为follower。 (5)服务器5启动，后面的逻辑同服务器4成为follower。
  + 推荐阅读
    + [【分布式】Zookeeper的Leader选举](https://www.cnblogs.com/leesf456/p/6107600.html)

**Redis**

+ Redis的应用场景

  + (1)缓存 (2)共享Session (3)消息队列系统 (4)分布式锁
  + 推荐阅读
    + [Redis常见的应用场景解析](https://zhuanlan.zhihu.com/p/29665317)

+ 单线程的Redis为什么快

  + (1)纯内存操作 (2)单线程操作，避免了频繁的上下文切换 (3)合理高效的数据结构 (4)采用了非阻塞I/O多路复用机制

+ Redis 的数据结构及使用场景（必考）

  + (1)String字符串:字符串类型是 Redis 最基础的数据结构，首先键都是字符串类型，而且 其他几种数据结构都是在字符串类型基础上构建的，我们常使用的 set key value 命令就是字符串。常用在缓存、计数、共享Session、限速等。

     (2)Hash哈希:在Redis中，哈希类型是指键值本身又是一个键值对 结构，形如value={{field1，value1}，...{fieldN，valueN}}，添加命令：hset key field value。哈希可以用来存放用户信息，比如实现购物车

     (3)List列表（双向链表）:列表（list）类型是用来存储多个有序的字符串。可以做简单的消息队列的功能。

     (4)Set集合：集合（set）类型也是用来保存多个的字符串元素，但和列表类型不一 样的是，集合中不允许有重复元素，并且集合中的元素是无序的，不能通过 索引下标获取元素。利用 Set 的交集、并集、差集等操作，可以计算共同喜好，全部的喜好，自己独有的喜好等功能。

     (5)Sorted Set有序集合（跳表实现）：Sorted Set 多了一个权重参数 Score，集合中的元素能够按 Score 进行排列。可以做排行榜应用，取 TOP N 操作。

+ zset跳表的数据结构（必考）

  + [Redis 为什么用跳表而不用平衡树？](https://juejin.im/post/57fa935b0e3dd90057c50fbc)

+ Redis的数据过期策略（必考）

  + Redis 中数据过期策略采用定期删除+惰性删除策略:
    +  (1)定期删除策略：Redis 启用一个定时器定时监视所有的 key，判断key是否过期，过期的话就删除。这种策略可以保证过期的 key 最终都会被删除，但是也存在严重的缺点：每次都遍历内存中所有的数据，非常消耗 CPU 资源，并且当 key 已过期，但是定时器还处于未唤起状态，这段时间内 key 仍然可以用。 
    + (2)惰性删除策略：在获取 key 时，先判断 key 是否过期，如果过期则删除。这种方式存在一个缺点：如果这个 key 一直未被使用，那么它一直在内存中，其实它已经过期了，会浪费大量的空间。 这两种策略天然的互补，结合起来之后，定时删除策略就发生了一些改变，不在是每次扫描全部的 key 了，而是随机抽取一部分 key 进行检查，这样就降低了对 CPU 资源的损耗，惰性删除策略互补了为检查到的key，基本上满足了所有要求。 但是有时候就是那么的巧，既没有被定时器抽取到，又没有被使用，这些数据又如何从内存中消失？没关系，
    + 还有内存淘汰机制，当内存不够用时，内存淘汰机制就会上场。淘汰策略分为： (1)当内存不足以容纳新写入数据时，新写入操作会报错。（Redis 默认策略） (2)当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的 Key。（LRU推荐使用） (3)当内存不足以容纳新写入数据时，在键空间中，随机移除某个 Key。 (4)当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除最近最少使用的 Key。这种情况一般是把 Redis 既当缓存，又做持久化存储的时候才用。 (5)当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某个 Key。 (6)当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，有更早过期时间的 Key 优先移除。

+ Redis的LRU过期策略的具体实现

  + Redis的LRU具体实现： 用栈的形式会导致执行select *的时候大量非热点数据占领头部数据，所以需要改进。 Redis每次按key获取一个值的时候，都会更新value中的lru字段为当前秒级别的时间戳。Redis初始的实现算法很简单，随机从dict中取出五个key,淘汰一个lru字段值最小的。 在3.0的时候，又改进了一版算法，首先第一次随机选取的key都会放入一个pool中(pool的大小为16),pool中的key是按lru大小顺序排列的。接下来每次随机选取的keylru值必须小于pool中最小的lru才会继续放入，直到将pool放满。放满之后，每次如果有新的key需要放入，需要将pool中lru最大的一个key取出。淘汰的时候，直接从pool中选取一个lru最小的值然后将其淘汰。
  + 推荐阅读
    + [Redis中的LRU淘汰策略分析](https://www.cnblogs.com/linxiyue/p/10945216.html)

+ 如何解决Redis缓存雪崩，缓存穿透问题

  + 缓存雪崩:
    + (1)使用 Redis 高可用架构：使用 Redis 集群来保证 Redis 服务不会挂掉
    + (2)缓存时间不一致，给缓存的失效时间，加上一个随机值，避免集体失效
    + (3)限流降级策略：有一定的备案，比如个性推荐服务不可用了，换成热点数据推荐服务
  + 缓存穿透
    + (1)在接口做校验
    +  (2)存null值（缓存击穿加锁）
    +  (3)布隆过滤器拦截： 将所有可能的查询key 先映射到布隆过滤器中，查询时先判断key是否存在布隆过滤器中，存在才继续向下执行，如果不存在，则直接返回。 布隆过滤器将值进行多次哈希bit存储，布隆过滤器说某个元素在，可能会被误判。布隆过滤器说某个元素不在，那么一定不在。
  + 推荐阅读
    + [缓存穿透，缓存击穿，缓存雪崩解决方案分析](https://blog.csdn.net/zeb_perfect/article/details/54135506)

+ Redis的持久化机制（必考）

  + redis为了保证效率，数据缓存在了内存中，但是会周期性的把更新的数据写入磁盘或者把修改操作写入追加的记录文件中，以保证数据的持久化。

    Redis的持久化策略有两种：

    +  (1)RDB：快照形式是直接把内存中的数据保存到一个dump的文件中，定时保存，保存策略。 当Redis需要做持久化时，Redis会fork一个子进程，子进程将数据写到磁盘上一个临时RDB文件中。当子进程完成写临时文件后，将原来的RDB替换掉。
    +  (2)AOF：把所有的对Redis的服务器进行修改的命令都存到一个文件里，命令的集合。 使用AOF做持久化，每一个写命令都通过write函数追加到appendonly.aof中。aof的默认策略是每秒钟fsync一次，在这种配置下，就算发生故障停机，也最多丢失一秒钟的数据。 缺点是对于相同的数据集来说，AOF的文件体积通常要大于RDB文件的体积。根据所使用的fsync策略，AOF的速度可能会慢于RDB。 Redis默认是快照RDB的持久化方式。

  + 推荐阅读

    + [一文看懂Redis的持久化原理](https://juejin.im/post/5b70dfcf518825610f1f5c16)

+ redis主从复制，主从同步

  + (1)从节点执行slaveofmasterIP，保存主节点信息

    (2)从节点中的定时任务发现主节点信息，建立和主节点的socket连接

    (3)从节点发送Ping信号，主节点返回Pong，两边能互相通信 

    (4)连接建立后，主节点将所有数据发送给从节点（数据同步）

    (5)主节点把当前的数据同步给从节点后，便完成了复制的建立过程。接下来，主节点就会持续的把写命令发送给从节点，保证主从数据一致性。

    主从刚刚连接的时候，进行全量同步（RDB）；全同步结束后，进行增量同步(AOF)。

  + 推荐阅读

    + [深入学习Redis（3）：主从复制](https://www.cnblogs.com/kismetv/p/9236731.html)

+ Redis和memcached的区别

  + (1)存储方式上：memcache会把数据全部存在内存之中，断电后会挂掉，数据不能超过内存大小。redis有部分数据存在硬盘上，这样能保证数据的持久性。

    (2)数据支持类型上：memcache对数据类型的支持简单，只支持简单的key-value，而redis支持五种数据类型。

    (3)用底层模型不同：它们之间底层实现方式以及与客户端之间通信的应用协议不一样。redis直接自己构建了VM机制，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求。 

    (4)value的大小：redis可以达到1GB，而memcache只有1MB。

+ redis并发竞争key的解决方案

  + (1)分布式锁+时间戳 (2)利用消息队列
  + 推荐阅读
    + [高并发架构系列：Redis并发竞争key的解决方案详解](https://zhuanlan.zhihu.com/p/52756935)

+ Redis与Mysql双写一致性方案

  + 先更新数据库，再删缓存。数据库的读操作的速度远快于写操作的，所以脏数据很难出现。可以对异步延时删除策略，保证读请求完成以后，再进行删除操作。
  + 推荐阅读
    + [Redis与Mysql双写一致性方案解析](https://zhuanlan.zhihu.com/p/59167071)

+ Redis的管道pipeline

  + 对于单线程阻塞式的Redis，Pipeline可以满足批量的操作，把多个命令连续的发送给Redis Server，然后一一解析响应结果。Pipelining可以提高批量处理性能，提升的原因主要是TCP连接中减少了“交互往返”的时间。 pipeline 底层是通过把所有的操作封装成流，redis有定义自己的出入输出流。在 sync() 方法执行操作，每次请求放在队列里面，解析响应包。

**Mysql**

+ 事务的基本要素(事务特性)

  + (1)原子性：事务是一个原子操作单元，其对数据的修改，要么全都执行，要么全都不执行

    (2)一致性：事务开始前和结束后，数据库的完整性约束没有被破坏。

    (3)隔离性：同一时间，只允许一个事务请求同一数据，不同的事务之间彼此没有任何干扰。

    (4)持久性：事务完成后，事务对数据库的所有更新将被保存到数据库，不能回滚。

+ 事务隔离级别、如何解决事务的并发问题(脏读，幻读)（必考）

  + [MySQL 四种事务隔离级的说明](https://www.cnblogs.com/zhoujinyi/p/3437475.html)
  + [数据库事务隔离级别-- 脏读、幻读、不可重复读](https://blog.csdn.net/JIESA/article/details/51317164)

+ MVCC,binlog,redolog,undolog都是什么，起什么作用（必考）

  + undolog 也就是我们常说的回滚日志文件 主要用于事务中执行失败，进行回滚，以及MVCC中对于数据历史版本的查看。由引擎层的InnoDB引擎实现,是逻辑日志,记录数据修改被修改前的值,比如"把id='B' 修改为id = 'B2' ，那么undo日志就会用来存放id ='B'的记录”。当一条数据需要更新前,会先把修改前的记录存储在undolog中,如果这个修改出现异常,则会使用undo日志来实现回滚操作,保证事务的一致性。当事务提交之后，undo log并不能立马被删除,而是会被放到待清理链表中,待判断没有事物用到该版本的信息时才可以清理相应undolog。它保存了事务发生之前的数据的一个版本，用于回滚，同时可以提供多版本并发控制下的读（MVCC），也即非锁定读。
  + redoLog 是重做日志文件是记录数据修改之后的值，用于持久化到磁盘中。redo log包括两部分：一是内存中的日志缓冲(redo log buffer)，该部分日志是易失性的；二是磁盘上的重做日志文件(redo log file)，该部分日志是持久的。由引擎层的InnoDB引擎实现,是物理日志,记录的是物理数据页修改的信息,比如“某个数据页上内容发生了哪些改动”。当一条数据需要更新时,InnoDB会先将数据更新，然后记录redoLog 在内存中，然后找个时间将redoLog的操作执行到磁盘上的文件上。不管是否提交成功我都记录，你要是回滚了，那我连回滚的修改也记录。它确保了事务的持久性。
  + MVCC多版本并发控制是MySQL中基于乐观锁理论实现隔离级别的方式，用于读已提交和可重复读取隔离级别的实现。在MySQL中，会在表中每一条数据后面添加两个字段：最近修改该行数据的事务ID，指向该行（undolog表中）回滚段的指针。Read View判断行的可见性，创建一个新事务时，copy一份当前系统中的活跃事务列表。意思是，当前不应该被本事务看到的其他事务id列表。
  + binlog由Mysql的Server层实现,是逻辑日志,记录的是sql语句的原始逻辑，比如"把id='B' 修改为id = ‘B2’。binlog会写入指定大小的物理文件中,是追加写入的,当前文件写满则会创建新的文件写入。 产生:事务提交的时候,一次性将事务中的sql语句,按照一定的格式记录到binlog中。用于复制和恢复在主从复制中，从库利用主库上的binlog进行重播(执行日志中记录的修改逻辑),实现主从同步。业务数据不一致或者错了，用binlog恢复。
  + 推荐阅读
    + [MySQL（5）| 五分钟搞清楚 MVCC 机制](https://juejin.im/post/5c68a4056fb9a049e063e0ab#heading-0)

+ binlog和redolog的区别

  + 区别：
    + redolog是在InnoDB存储引擎层产生，而binlog是MySQL数据库的上层服务层产生的。
    + 两种日志记录的内容形式不同。MySQL的binlog是逻辑日志，其记录是对应的SQL语句。而innodb存储引擎层面的重做日志是物理日志。
    + 两种日志与记录写入磁盘的时间点不同，binlog日志只在事务提交完成后进行一次写入。而innodb存储引擎的重做日志在事务进行中不断地被写入，并日志不是随事务提交的顺序进行写入的。
    + binlog不是循环使用，在写满或者重启之后，会生成新的binlog文件，redolog是循环使用。
    + binlog可以作为恢复数据使用，主从复制搭建，redolog作为异常宕机或者介质故障后的数据恢复使用。
  + 推荐阅读：
    + [一文带你看懂binlog和redo log](https://www.jianshu.com/p/907f9002442e)

+ Mysql如何保证一致性和持久性

  + MySQL为了保证ACID中的一致性和持久性，使用了WAL(Write-Ahead Logging,先写日志再写磁盘)。Redo log就是一种WAL的应用。当数据库忽然掉电，再重新启动时，MySQL可以通过Redo log还原数据。也就是说，每次事务提交时，不用同步刷新磁盘数据文件，只需要同步刷新Redo log就足够了。

+ InnoDB的行锁/表锁

+ myisam和innodb的区别，什么时候选择myisam

+ 为什么选择B+树作为索引结构（必考）

+ 索引B+树的叶子节点都可以存哪些东西（必考）

+ 查询在什么时候不走（预期中的）索引（必考）

+ sql如何优化

+ explain是如何解析sql的

+ order by原理

**JVM**

+ 1. 运行时数据区域（内存模型）（必考）
+ 2. 垃圾回收机制（必考）
+ 3. 垃圾回收算法（必考）
+ 4. Minor GC和Full GC触发条件
+ 5. GC中Stop the world（STW）
+ 6. 各垃圾回收器的特点及区别
+ 7. 双亲委派模型
+ 8. JDBC和双亲委派模型关系

**Java基础**

+ 1. HashMap和ConcurrentHashMap区别（必考）
+ 2. ConcurrentHashMap的数据结构（必考）
+ 3. 高并发HashMap的环是如何产生的
+ 4. volatile作用（必考）
+ 5. Atomic类如何保证原子性（CAS操作）（必考）
+ 6. synchronized和Lock的区别（必考）
+ 7. 为什么要使用线程池（必考）
+ 8. 核心线程池ThreadPoolExecutor的参数（必考）
+ 9. ThreadPoolExecutor的工作流程（必考）
+ 10. 如何控制线程池线程的优先级
+ 11. 线程之间如何通信
+ 12. Boolean占几个字节
+ 13. jdk1.8/jdk1.7都分别新增了哪些特性
+ 14. Exception和Error

**Spring**

+ 1. Spring的IOC/AOP的实现（必考）
+ 2. 动态代理的实现方式（必考）
+ 3. Spring的后置处理器
+ 4. Spring的@Transactional如何实现的（必考）
+ 5. Spring的事务传播级别

**其他**

+ 1. 高并发系统的限流如何实现
+ 2. 高并发秒杀系统的设计
+ 3. 负载均衡如何设计

**补充**

另外还会考一些计算机网络，操作系统啊之类的。像消息队列，RPC框架这种考的比较少。计算机网络就是分层啊，tcp/udp啊，三次握手之类的。操作系统就是进程与线程啊，进程的数据结构以及如何通信之类的。数据结构的排序算法也比较常考，考的话一定会让你手写个快排。剩下的算法题就靠LeetCode的积累了。其实非算法岗考的算法题都蛮简单的，很多题完全就是考察你智力是否正常，稍微难点的涉及到一些算法思想的按照LeetCode题目类型的分类，每种题做一两道基本就能完全应付面试了。


**面试感受及评价**

除了外企，体验最好的就是阿里。绝对的脱颖而出，无论是面试官的专业程度还是面试官对参与面试人员的态度都完全突出于其他公司。非常的尊重人，以及会引导我去作出正确的回答，唯一就是阿里的HR是非常强势的，永远有一票否决权。而有些公司面试官会故意误导你，想方设法让你说出错误的答案，并且有些态度极其傲慢，让人感觉很不尊重人。这里点名批评面试体验最差的两家公司：美团和Boss直聘。

外企的话，体验都很好，但是我都还没面试完，后面会更新的。微软是英文面的，亚马逊不是。这俩都是以算法为主，微软除了算法还聊了操作系统和计算机网络，亚马逊聊了较长时间的项目细节。


**最后**

最后说下自己的情况，17年在京东实习，19年7月离职。正式工作时间很短，就一年（算实习两年），而且19年有半年的时间准备考研所以有半年的空档期，这也是为什么我被很多HR挂了的原因。虽然Offer没拿几个，但是一半多都面到HR面了，所以对于两三年经验的感觉整理的问题还是比较有代表性的。